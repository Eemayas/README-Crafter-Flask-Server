{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jmaP2oF7tO6"
      },
      "outputs": [],
      "source": [
        "collab = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2-jeKtF8ntD"
      },
      "source": [
        "<!-- @format -->\n",
        "\n",
        "# Ollama Step-Up\n",
        "\n",
        "This section installs necessary packages, sets up the Ollama API, and runs the server in a separate thread.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbMONtj26vY0"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "import subprocess\n",
        "import threading\n",
        "import os\n",
        "\n",
        "# Install necessary packages and start Ollama API server\n",
        "!sudo apt-get install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "!ollama pull llama3.1:8b\n",
        "%pip install -U lightrag[ollama]\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mutIqWx_gBn0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import threading\n",
        "\n",
        "\n",
        "def ollama():\n",
        "    \"\"\"\n",
        "    Start the Ollama API server in a separate thread with appropriate environment settings based on the execution context.\n",
        "\n",
        "    The function sets environment variables for the Ollama server and starts the server using the `subprocess.Popen` method.\n",
        "    It configures the server to listen on different hosts based on whether the script is running in a Colab environment or not.\n",
        "\n",
        "    Environment Variables:\n",
        "    - 'OLLAMA_HOST': The address and port on which the Ollama server will listen.\n",
        "    - 'OLLAMA_ORIGINS': The allowed origins for requests to the Ollama server.\n",
        "\n",
        "    If running in a Colab environment, the server is set to listen on '0.0.0.0:11434'. Otherwise, it listens on '127.0.0.1:11434'.\n",
        "\n",
        "    Note:\n",
        "    - Ensure that the `ollama` command is available in the system path for `subprocess.Popen` to work correctly.\n",
        "    - This function will not block the main thread as it runs the server in a separate thread.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    if collab:\n",
        "        os.environ[\"OLLAMA_HOST\"] = \"0.0.0.0:11434\"\n",
        "        os.environ[\"OLLAMA_ORIGINS\"] = \"*\"\n",
        "        subprocess.Popen([\"ollama\", \"serve\"])\n",
        "    else:\n",
        "        os.environ[\"OLLAMA_HOST\"] = \"127.0.0.1:11434\"\n",
        "        os.environ[\"OLLAMA_ORIGINS\"] = \"*\"\n",
        "        subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "\n",
        "# Start Ollama API server in a separate thread\n",
        "ollama_thread = threading.Thread(target=ollama)\n",
        "ollama_thread.start()\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Setting Up Simple Question-Answering Component\n",
        "\n",
        "This section sets up a simple QA component using the Ollama model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ka7vU2NOgyLz"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "from lightrag.core.generator import Generator\n",
        "from lightrag.core.component import Component\n",
        "from lightrag.core.model_client import ModelClient\n",
        "\n",
        "# Template for the QA model\n",
        "qa_template = r\"\"\"<SYS>\n",
        "You are a helpful assistant.\n",
        "</SYS>\n",
        "User: {{input_str}}\n",
        "You:\"\"\"\n",
        "\n",
        "# Define the SimpleQA class\n",
        "\n",
        "\n",
        "class SimpleQA(Component):\n",
        "    \"\"\"\n",
        "    A simple Question-Answering (QA) component built on top of the lightrag framework.\n",
        "\n",
        "    This class initializes a text generation component using the provided model client,\n",
        "    model configurations, and a predefined QA template. The component is designed to\n",
        "    generate responses to user input by following the QA template.\n",
        "\n",
        "    Attributes:\n",
        "    - generator (Generator): An instance of the Generator class, responsible for\n",
        "      generating text based on the model, input data, and template.\n",
        "\n",
        "    Methods:\n",
        "    - call(input: dict) -> str: Synchronously generate a response based on the user input.\n",
        "    - acall(input: dict) -> str: Asynchronously generate a response based on the user input.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_client: ModelClient, model_kwargs: dict):\n",
        "        super().__init__()\n",
        "        self.generator = Generator(\n",
        "            model_client=model_client,\n",
        "            model_kwargs=model_kwargs,\n",
        "            template=qa_template,\n",
        "        )\n",
        "\n",
        "    def call(self, input: dict) -> str:\n",
        "        \"\"\"\n",
        "        Synchronously generate a response based on the user input.\n",
        "\n",
        "        Parameters:\n",
        "        - input (dict): A dictionary containing the input string under the key 'input_str'.\n",
        "\n",
        "        Returns:\n",
        "        - str: The generated response as a string.\n",
        "        \"\"\"\n",
        "        return self.generator.call({\"input_str\": str(input)})\n",
        "\n",
        "    async def acall(self, input: dict) -> str:\n",
        "        \"\"\"\n",
        "        Asynchronously generate a response based on the user input.\n",
        "\n",
        "        Parameters:\n",
        "        - input (dict): A dictionary containing the input string under the key 'input_str'.\n",
        "\n",
        "        Returns:\n",
        "        - str: The generated response as a string.\n",
        "        \"\"\"\n",
        "        return await self.generator.acall({\"input_str\": str(input)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Running a Simple QA Example\n",
        "\n",
        "This section demonstrates how to use the SimpleQA component to answer a basic question.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "TXm9TW4fhZ86",
        "outputId": "ae93e77b-14fd-4c2c-c0a0-fdc6390bb132"
      },
      "outputs": [],
      "source": [
        "from lightrag.components.model_client import OllamaClient\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Initialize the SimpleQA component with the Ollama model\n",
        "model = {\n",
        "    \"model_client\": OllamaClient(),  # Instantiate the model client for Ollama\n",
        "    # Specify the model and its version to be used\n",
        "    \"model_kwargs\": {\"model\": \"llama3.1:8b\"},\n",
        "}\n",
        "# Create an instance of SimpleQA with the provided model configuration\n",
        "simple_qa = SimpleQA(**model)\n",
        "\n",
        "# Ask a simple question and display the answer\n",
        "# Generate a response using the SimpleQA component\n",
        "output = simple_qa(\"what is 2+2\")\n",
        "# Display the answer in Markdown format\n",
        "display(Markdown(f\"**Answer:** {output.data}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "# Constants\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Ignore List\n",
        "\n",
        "This section defines the list of directories, files, and file extensions to be ignored when processing the repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7_9xlFRH1wQY"
      },
      "outputs": [],
      "source": [
        "# List of file extensions to be ignored when constructuing folder structure,\n",
        "# as they are unlikely to contain relevant information.\n",
        "ignore_list_folder_structure = [\n",
        "    # General\n",
        "    \".git\",  # Git repository metadata\n",
        "    \"node_modules\",  # Node.js modules\n",
        "    \".idea\",  # JetBrains IDE project files\n",
        "    \".vscode\",  # Visual Studio Code settings\n",
        "    \"__pycache__\",  # Python bytecode cache\n",
        "    \".DS_Store\",  # macOS directory metadata\n",
        "    \".env\",  # Environment variable files\n",
        "    \"venv\",  # Python virtual environment\n",
        "    \"build\",  # Build output directories\n",
        "    \"dist\",  # Distribution directories\n",
        "    \"target\",  # Output from Java and Rust builds\n",
        "    \".pytest_cache\",  # Pytest cache files\n",
        "    \"*.log\",  # Log files\n",
        "    \"*.tmp\",  # Temporary files\n",
        "    # Python\n",
        "    \"*.pyc\",  # Compiled Python files\n",
        "    \".mypy_cache\",  # Mypy type checker cache\n",
        "    \".tox\",  # Tox environment\n",
        "    # JavaScript/Node.js\n",
        "    \"npm-debug.log\",  # NPM debug logs\n",
        "    \"yarn-error.log\",  # Yarn error logs\n",
        "    \".parcel-cache\",  # Parcel bundler cache\n",
        "    \"coverage\",  # Code coverage reports\n",
        "    \".next\",  # Next.js build directory\n",
        "    \"out\",  # Output directory for Next.js\n",
        "    # Java\n",
        "    \"*.class\",  # Compiled Java classes\n",
        "    \"*.jar\",  # JAR files\n",
        "    \"*.war\",  # WAR files\n",
        "    \".settings\",  # Eclipse settings\n",
        "    \".classpath\",  # Eclipse classpath\n",
        "    \".project\",  # Eclipse project file\n",
        "    # C/C++\n",
        "    \"*.o\",  # Object files\n",
        "    \"*.a\",  # Static libraries\n",
        "    \"*.so\",  # Shared libraries\n",
        "    \"*.out\",  # Executable files\n",
        "    \"*.exe\",  # Windows executables\n",
        "    \"CMakeFiles\",  # CMake build files\n",
        "    \"CMakeCache.txt\",  # CMake cache\n",
        "    \"*.dSYM\",  # macOS debug symbols\n",
        "    \"*.pdb\",  # Windows debug symbols\n",
        "    # Rust\n",
        "    \"*.rlib\",  # Rust libraries\n",
        "    \"Cargo.lock\",  # Cargo lock file\n",
        "    # Go\n",
        "    \"bin\",  # Binary output directory\n",
        "    \"pkg\",  # Package output directory\n",
        "    \"*.test\",  # Go test binaries\n",
        "    \"vendor\",  # Vendor directory (if not used)\n",
        "    # Ruby\n",
        "    \".bundle\",  # Bundler directory\n",
        "    \"vendor/bundle\",  # Bundled gems\n",
        "    \"log\",  # Log files\n",
        "    \"tmp\",  # Temporary files\n",
        "    \".gem\",  # RubyGems metadata\n",
        "    # PHP\n",
        "    \"vendor\",  # Composer dependencies\n",
        "    \".phpunit.result.cache\",  # PHPUnit result cache\n",
        "    # Android\n",
        "    \".gradle\",  # Gradle files\n",
        "    \"*.apk\",  # Android package\n",
        "    \"*.ap_ \",  # Android resources package\n",
        "    \"local.properties\",  # Android SDK settings\n",
        "    # .NET/C#\n",
        "    \"bin\",  # Binary output directory\n",
        "    \"obj\",  # Object files directory\n",
        "    \"*.dll\",  # DLL files\n",
        "    \"*.user\",  # User settings\n",
        "    \"packages\",  # NuGet packages\n",
        "    # LaTeX\n",
        "    \"*.aux\",  # Auxiliary files\n",
        "    \"*.toc\",  # Table of contents\n",
        "    \"*.out\",  # Auxiliary output files\n",
        "    \"*.synctex.gz\",  # SyncTeX file\n",
        "    \"*.fls\",  # LaTeX build files\n",
        "    \"*.fdb_latexmk\",  # LaTeX build files\n",
        "]\n",
        "\n",
        "\n",
        "# List of file extensions to be ignored based on file types:\n",
        "ignore_list_extensions = [\n",
        "    # Image formats\n",
        "    \".png\",\n",
        "    \".jpg\",\n",
        "    \".jpeg\",\n",
        "    \".gif\",\n",
        "    \".bmp\",\n",
        "    \".svg\",\n",
        "    \".tiff\",\n",
        "    \".webp\",\n",
        "    \".heif\",\n",
        "    \".heic\",\n",
        "    \".ico\",\n",
        "    \".raw\",\n",
        "    \".psd\",\n",
        "    # Audio formats\n",
        "    \".mp3\",\n",
        "    \".wav\",\n",
        "    \".flac\",\n",
        "    \".aac\",\n",
        "    \".ogg\",\n",
        "    \".m4a\",\n",
        "    \".wma\",\n",
        "    \".aiff\",\n",
        "    \".alac\",\n",
        "    \".pcm\",\n",
        "    # Video formats\n",
        "    \".mp4\",\n",
        "    \".avi\",\n",
        "    \".mkv\",\n",
        "    \".mov\",\n",
        "    \".wmv\",\n",
        "    \".flv\",\n",
        "    \".webm\",\n",
        "    \".m4v\",\n",
        "    \".mpg\",\n",
        "    \".mpeg\",\n",
        "    \".3gp\",\n",
        "    \".ogv\",\n",
        "    \".rm\",\n",
        "    \".swf\"\n",
        "    # Binary files\n",
        "    \".exe\",\n",
        "    \".dll\",\n",
        "    \".bin\",\n",
        "    \".iso\",\n",
        "    \".img\",\n",
        "    # System files\n",
        "    \".sys\",\n",
        "    \".log\",\n",
        "    \".bak\",\n",
        "    \".tmp\",\n",
        "    \".ini\",\n",
        "    # Font files\n",
        "    \".ttf\",\n",
        "    \".otf\",\n",
        "    \".woff\",\n",
        "    \".woff2\",\n",
        "    # Miscellaneous\n",
        "    \".ico\",\n",
        "    \".svg\",\n",
        "    \".pdf\",\n",
        "    \".doc\",\n",
        "    \".docx\",\n",
        "    \".xls\",\n",
        "    \".xlsx\",\n",
        "    \".ppt\",\n",
        "    \".pptx\",\n",
        "]\n",
        "\n",
        "# List of additional file extensions to be ignored when searching for API references,\n",
        "# as they are unlikely to contain relevant API information.\n",
        "\n",
        "api_additional_extensions = [\n",
        "    # Text and document formats\n",
        "    \".copy\",\n",
        "    \".local\",\n",
        "    \".json\",\n",
        "    \".config\",\n",
        "    \".md\",\n",
        "    \".txt\",\n",
        "    \".log\",\n",
        "    \".yml\",\n",
        "    \".yaml\",\n",
        "    \".xml\",\n",
        "    \".ini\",\n",
        "    \".pdf\",\n",
        "    \".csv\",\n",
        "    \".tsv\",\n",
        "    # Font formats\n",
        "    \".woff\",\n",
        "    \".woff2\",\n",
        "    \".ttf\",\n",
        "    \".eot\",\n",
        "    \".otf\",\n",
        "    # Configuration and map files\n",
        "    \".config.ts\",\n",
        "    \".map\",\n",
        "    \".lock\",\n",
        "    # Styling files\n",
        "    \".css\",\n",
        "    \".scss\",\n",
        "    \".sass\",\n",
        "    \".less\",\n",
        "    \".styl\",\n",
        "    \".pcss\",\n",
        "    \".postcss\",\n",
        "]\n",
        "\n",
        "# Combine ignore_extensions and api_additional_extensions\n",
        "\n",
        "api_ignore_extensions = ignore_list_extensions + api_additional_extensions\n",
        "\n",
        "# Additional specific ignores for API references\n",
        "specific_ignores_api = [\".gitignore\", \".config.js\", \".config.ts\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Project Icons\n",
        "\n",
        "This section defines the map of the project type and project icons\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "project_icons = {\n",
        "    \"ecommerce\": {\n",
        "        \"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/shopping-basket-2.png\"\n",
        "    },\n",
        "    \"banking\": {\"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/bank.png\"},\n",
        "    \"school\": {\"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/school.png\"},\n",
        "    \"education\": {\n",
        "        \"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/graduation-cap.png\"\n",
        "    },\n",
        "    \"work\": {\"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/briefcase.png\"},\n",
        "    \"healthcare\": {\n",
        "        \"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/hospital-room.png\"\n",
        "    },\n",
        "    \"real_estate\": {\"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/home.png\"},\n",
        "    \"travel\": {\"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/passport.png\"},\n",
        "    \"social_media\": {\n",
        "        \"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/share.png\"\n",
        "    },\n",
        "    \"fitness\": {\"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/dumbbell.png\"},\n",
        "    \"news\": {\"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/news.png\"},\n",
        "    \"entertainment\": {\n",
        "        \"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/clapperboard.png\"\n",
        "    },\n",
        "    \"food_delivery\": {\n",
        "        \"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/food-delivery.png\"\n",
        "    },\n",
        "    \"finance\": {\"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/money.png\"},\n",
        "    \"transportation\": {\n",
        "        \"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/bus.png\"\n",
        "    },\n",
        "    \"hospitality\": {\"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/hotel.png\"},\n",
        "    \"music\": {\n",
        "        \"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/musical-notes.png\"\n",
        "    },\n",
        "    \"gaming\": {\"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/controller.png\"},\n",
        "    \"environment\": {\n",
        "        \"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/earth-planet.png\"\n",
        "    },\n",
        "    \"nonprofit\": {\"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/charity.png\"},\n",
        "    \"photography\": {\n",
        "        \"icon\": \"https://img.icons8.com/nolan/512/1A6DFF/C822FF/camera.png\"\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Language, Framework, Tools Extension List\n",
        "\n",
        "This section defines the list of Language, Framework, Tools Extension List\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define known file extensions and configurations for different languages and tools\n",
        "extensions = {\n",
        "    \"Python\": [\".py\"],\n",
        "    \"JavaScript\": [\".js\", \".jsx\", \".ts\", \".tsx\"],\n",
        "    \"Java\": [\".java\", \".class\", \".jar\", \".xml\"],\n",
        "    \"C++\": [\".c\", \".cpp\", \".h\", \".hpp\", \".cc\", \".cxx\"],\n",
        "    \"C#\": [\".cs\", \".csproj\"],\n",
        "    \"Ruby\": [\".rb\", \".gemspec\", \".ru\"],\n",
        "    \"PHP\": [\".php\", \".phtml\"],\n",
        "    \"Swift\": [\".swift\"],\n",
        "    \"Go\": [\".go\"],\n",
        "    \"Rust\": [\".rs\"],\n",
        "    \"Kotlin\": [\".kt\", \".kts\"],\n",
        "    \"R\": [\".R\", \".r\", \".rmd\"],\n",
        "    \"SQL\": [\".sql\"],\n",
        "    \"HTML5\": [\".html\", \".htm\", \".css\"],\n",
        "    \"CSS3\": [\".css\"],\n",
        "    \"TypeScript\": [\".ts\", \".tsx\"],\n",
        "    \"Scala\": [\".scala\", \".sbt\"],\n",
        "    \"Perl\": [\".pl\", \".pm\"],\n",
        "    \"Objective-C\": [\".m\", \".h\"],\n",
        "    \"Shell\": [\".sh\", \".bash\", \".zsh\"],\n",
        "    \"PowerShell\": [\".ps1\"],\n",
        "    \"Haskell\": [\".hs\", \".cabal\"],\n",
        "    \"Lua\": [\".lua\"],\n",
        "    \"Erlang\": [\".erl\", \".hrl\"],\n",
        "    \"Groovy\": [\".groovy\", \".gvy\"],\n",
        "    \"VHDL\": [\".vhdl\", \".vhd\"],\n",
        "}\n",
        "frameworks_extensions = {\n",
        "    \"React\": [\".jsx\", \".tsx\"],\n",
        "    \"Angular\": [\"angular.json\"],\n",
        "    \"Vue.js\": [\".vue\"],\n",
        "    \"Django\": [\"settings.py\", \"urls.py\"],\n",
        "    \"Flask\": [\".py\"],\n",
        "    \"Spring\": [\".xml\"],\n",
        "    \"Maven\": [\"pom.xml\"],\n",
        "    \"Gradle\": [\"build.gradle\", \"settings.gradle\"],\n",
        "    \"Rails\": [\"Gemfile\", \"config.ru\"],\n",
        "    \"Laravel\": [\"composer.json\"],\n",
        "    \"Symfony\": [\"composer.json\"],\n",
        "    \"Next.js\": [\"next.config.js\"],\n",
        "    \"Gatsby\": [\"gatsby-config.js\", \"gatsby-node.js\"],\n",
        "    \"Svelte\": [\".svelte\"],\n",
        "    \"Bootstrap\": [\"bootstrap.min.css\", \"bootstrap.min.js\"],\n",
        "    \"Jasmine\": [\"jasmine.json\"],\n",
        "    \"Mocha\": [\"mocha.opts\"],\n",
        "    \"Express\": [\"app.js\", \"server.js\"],\n",
        "    \"Sails.js\": [\"config/\", \"api/\"],\n",
        "    \"ASP.NET\": [\".cshtml\", \".vbhtml\", \"web.config\"],\n",
        "    \"Spring Boot\": [\"application.properties\", \"application.yml\"],\n",
        "    \"Quasar\": [\"quasar.conf.js\"],\n",
        "    \"Electron\": [\"main.js\", \"package.json\"],\n",
        "}\n",
        "tools_extensions = {\n",
        "    \"Webpack\": [\"webpack.config.js\"],\n",
        "    \"Docker\": [\"Dockerfile\"],\n",
        "    \"CI/CD\": [\".github/workflows/ci.yml\", \".gitlab-ci.yml\", \"Jenkinsfile\"],\n",
        "    \"Babel\": [\".babelrc\", \"babel.config.json\"],\n",
        "    \"ESLint\": [\".eslintrc\", \".eslintrc.js\", \".eslintrc.json\"],\n",
        "    \"Prettier\": [\".prettierrc\", \".prettierrc.json\"],\n",
        "    \"Jest\": [\"jest.config.js\", \"jest.config.json\"],\n",
        "    \"Travis CI\": [\".travis.yml\"],\n",
        "    \"CircleCI\": [\".circleci/config.yml\"],\n",
        "    \"Appveyor\": [\"appveyor.yml\"],\n",
        "    \"Composer\": [\"composer.json\", \"composer.lock\"],\n",
        "    \"Puppet\": [\"manifest.pp\", \"Puppetfile\"],\n",
        "    \"Ansible\": [\"ansible.cfg\", \"playbook.yml\"],\n",
        "    \"Kubernetes\": [\"deployment.yaml\", \"service.yaml\"],\n",
        "    \"Terraform\": [\".tf\", \"main.tf\"],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdituG2_1joM"
      },
      "source": [
        "<!-- @format -->\n",
        "\n",
        "# Extraction of the needed data using Github API and Ollama\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Package Installations\n",
        "\n",
        "This section installs additional necessary Python packages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v-tRbgP61lqt"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "# %pip install nest_asyncio\n",
        "# %pip install prettytable\n",
        "# %pip install tqdm\n",
        "# %pip install -U lightrag[ollama]\n",
        "# %pip install aiohttp\n",
        "# %pip install pandas\n",
        "# %pip install openpyxl\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LARgwnme1qRc"
      },
      "outputs": [],
      "source": [
        "repository_url = \"https://github.com/Eemayas/Daraz_Scraper\"\n",
        "# repository_url = \"https://github.com/embraceitmobile/animated_tree_view\"\n",
        "# repository_url = \"https://github.com/earthPerson-001/Simple-Pendulum-Simulation-Using-OpenGL\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Cloning GitHub Repo\n",
        "\n",
        "This Section clone the repo into the targeted folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "\n",
        "async def clone_github_repo(\n",
        "    repository_url: str, target_folder: str = \"Github_repos\"\n",
        ") -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Clone a GitHub repository to a specific folder and remove the .git folder.\n",
        "\n",
        "    Args:\n",
        "        repository_url (str): The URL of the GitHub repository to clone.\n",
        "        target_folder (str, optional): The target directory to clone the repository into. Defaults to 'Github_repos'.\n",
        "\n",
        "    Returns:\n",
        "        Optional[str]: The path to the cloned repository, or None if cloning failed.\n",
        "    \"\"\"\n",
        "    # Extract the repository name from the URL\n",
        "    repo_name = repository_url.split(\"/\")[-1]\n",
        "    target_path = os.path.join(target_folder, repo_name)\n",
        "\n",
        "    if not os.path.exists(target_path):\n",
        "        # Ensure the target folder exists\n",
        "        os.makedirs(target_folder, exist_ok=True)\n",
        "        print(f\"Cloning repository from {repository_url} into {target_path}...\")\n",
        "\n",
        "        try:\n",
        "            # Run the git clone command to clone the repository\n",
        "            subprocess.run([\"git\", \"clone\", repository_url, target_path], check=True)\n",
        "            print(f\"Repository cloned into {target_path}/\")\n",
        "\n",
        "            # Remove the .git folder to clean up the cloned repository\n",
        "            git_folder_path = os.path.join(target_path, \".git\")\n",
        "            if os.path.exists(git_folder_path):\n",
        "                shutil.rmtree(git_folder_path)\n",
        "                print(f\"Removed .git folder from {target_path}/\")\n",
        "\n",
        "            # Return the path to the cloned repository\n",
        "            return target_path\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            # Handle errors that occur during the cloning process\n",
        "            print(f\"Error cloning repository: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        # If the repository folder already exists, skip the cloning process\n",
        "        print(f\"Repository folder '{target_path}' already exists. Skipping clone.\")\n",
        "        return target_path\n",
        "\n",
        "\n",
        "# Clone the repository asynchronously\n",
        "cloned_repo_path = await clone_github_repo(repository_url=repository_url)\n",
        "print(cloned_repo_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EZQUmYh8tnq"
      },
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### GitHub Metadata Extraction\n",
        "\n",
        "This section defines functions to extract metadata from a GitHub repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI7qFwgB1vx8",
        "outputId": "4ee0d8fd-619c-447d-8128-860de95bcbe8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from prettytable import PrettyTable\n",
        "import asyncio\n",
        "import aiohttp\n",
        "from typing import Any, Optional, List, Dict\n",
        "from dataclasses import dataclass\n",
        "import nest_asyncio\n",
        "\n",
        "# Enable asyncio to be used in Jupyter Notebooks\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Define dataclasses for storing metadata\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Contributor:\n",
        "    name: str\n",
        "    profile_url: str\n",
        "    avatar_url: str\n",
        "    contributions: str\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class RepositoryMetadata:\n",
        "    # Define fields for repository metadata\n",
        "    id: int\n",
        "    node_id: str\n",
        "    name: str\n",
        "    full_name: str\n",
        "    private: bool\n",
        "    owner: Dict[str, Any]\n",
        "    html_url: str\n",
        "    description: Optional[str]\n",
        "    fork: bool\n",
        "    url: str\n",
        "    forks_url: str\n",
        "    keys_url: str\n",
        "    collaborators_url: str\n",
        "    teams_url: str\n",
        "    hooks_url: str\n",
        "    issue_events_url: str\n",
        "    events_url: str\n",
        "    assignees_url: str\n",
        "    branches_url: str\n",
        "    tags_url: str\n",
        "    blobs_url: str\n",
        "    git_tags_url: str\n",
        "    git_refs_url: str\n",
        "    trees_url: str\n",
        "    statuses_url: str\n",
        "    languages_url: str\n",
        "    stargazers_url: str\n",
        "    contributors_url: str\n",
        "    subscribers_url: str\n",
        "    subscription_url: str\n",
        "    commits_url: str\n",
        "    git_commits_url: str\n",
        "    comments_url: str\n",
        "    issue_comment_url: str\n",
        "    contents_url: str\n",
        "    compare_url: str\n",
        "    merges_url: str\n",
        "    archive_url: str\n",
        "    downloads_url: str\n",
        "    issues_url: str\n",
        "    pulls_url: str\n",
        "    milestones_url: str\n",
        "    notifications_url: str\n",
        "    labels_url: str\n",
        "    releases_url: str\n",
        "    deployments_url: str\n",
        "    created_at: str\n",
        "    updated_at: str\n",
        "    pushed_at: str\n",
        "    git_url: str\n",
        "    ssh_url: str\n",
        "    clone_url: str\n",
        "    svn_url: str\n",
        "    homepage: Optional[str]\n",
        "    size: int\n",
        "    stargazers_count: int\n",
        "    watchers_count: int\n",
        "    language: Optional[str]\n",
        "    has_issues: bool\n",
        "    has_projects: bool\n",
        "    has_downloads: bool\n",
        "    has_wiki: bool\n",
        "    has_pages: bool\n",
        "    has_discussions: bool\n",
        "    forks_count: int\n",
        "    mirror_url: Optional[str]\n",
        "    archived: bool\n",
        "    disabled: bool\n",
        "    open_issues_count: int\n",
        "    license: Optional[Dict[str, Any]]\n",
        "    allow_forking: bool\n",
        "    is_template: bool\n",
        "    web_commit_signoff_required: bool\n",
        "    topics: List[str]\n",
        "    visibility: str\n",
        "    forks: int\n",
        "    open_issues: int\n",
        "    watchers: int\n",
        "    default_branch: str\n",
        "    temp_clone_token: Optional[str]\n",
        "    network_count: int\n",
        "    subscribers_count: int\n",
        "    contributors: List[Contributor]\n",
        "\n",
        "\n",
        "# Parse repository metadata and contributors\n",
        "\n",
        "\n",
        "def _parse_repository_metadata(\n",
        "    repo_data: dict, contributors: List[Contributor]\n",
        ") -> RepositoryMetadata:\n",
        "    \"\"\"\n",
        "    Parse the JSON data returned by the GitHub API into a RepositoryMetadata object.\n",
        "\n",
        "    Args:\n",
        "        repo_data (dict): The repository metadata returned by the GitHub API.\n",
        "        contributors (List[Contributor]): A list of Contributor objects.\n",
        "\n",
        "    Returns:\n",
        "        RepositoryMetadata: An object containing the parsed repository metadata.\n",
        "    \"\"\"\n",
        "    owner_info = repo_data.get(\"owner\", {}) or {}\n",
        "    license_info = repo_data.get(\"license\", {}) or {}\n",
        "\n",
        "    return RepositoryMetadata(\n",
        "        id=repo_data.get(\"id\", 0),\n",
        "        node_id=repo_data.get(\"node_id\", \"\"),\n",
        "        name=repo_data.get(\"name\", \"\"),\n",
        "        full_name=repo_data.get(\"full_name\", \"\"),\n",
        "        private=repo_data.get(\"private\", False),\n",
        "        owner=owner_info,\n",
        "        html_url=repo_data.get(\"html_url\", \"\"),\n",
        "        description=repo_data.get(\"description\", \"\"),\n",
        "        fork=repo_data.get(\"fork\", False),\n",
        "        url=repo_data.get(\"url\", \"\"),\n",
        "        forks_url=repo_data.get(\"forks_url\", \"\"),\n",
        "        keys_url=repo_data.get(\"keys_url\", \"\"),\n",
        "        collaborators_url=repo_data.get(\"collaborators_url\", \"\"),\n",
        "        teams_url=repo_data.get(\"teams_url\", \"\"),\n",
        "        hooks_url=repo_data.get(\"hooks_url\", \"\"),\n",
        "        issue_events_url=repo_data.get(\"issue_events_url\", \"\"),\n",
        "        events_url=repo_data.get(\"events_url\", \"\"),\n",
        "        assignees_url=repo_data.get(\"assignees_url\", \"\"),\n",
        "        branches_url=repo_data.get(\"branches_url\", \"\"),\n",
        "        tags_url=repo_data.get(\"tags_url\", \"\"),\n",
        "        blobs_url=repo_data.get(\"blobs_url\", \"\"),\n",
        "        git_tags_url=repo_data.get(\"git_tags_url\", \"\"),\n",
        "        git_refs_url=repo_data.get(\"git_refs_url\", \"\"),\n",
        "        trees_url=repo_data.get(\"trees_url\", \"\"),\n",
        "        statuses_url=repo_data.get(\"statuses_url\", \"\"),\n",
        "        languages_url=repo_data.get(\"languages_url\", \"\"),\n",
        "        stargazers_url=repo_data.get(\"stargazers_url\", \"\"),\n",
        "        contributors_url=repo_data.get(\"contributors_url\", \"\"),\n",
        "        subscribers_url=repo_data.get(\"subscribers_url\", \"\"),\n",
        "        subscription_url=repo_data.get(\"subscription_url\", \"\"),\n",
        "        commits_url=repo_data.get(\"commits_url\", \"\"),\n",
        "        git_commits_url=repo_data.get(\"git_commits_url\", \"\"),\n",
        "        comments_url=repo_data.get(\"comments_url\", \"\"),\n",
        "        issue_comment_url=repo_data.get(\"issue_comment_url\", \"\"),\n",
        "        contents_url=repo_data.get(\"contents_url\", \"\"),\n",
        "        compare_url=repo_data.get(\"compare_url\", \"\"),\n",
        "        merges_url=repo_data.get(\"merges_url\", \"\"),\n",
        "        archive_url=repo_data.get(\"archive_url\", \"\"),\n",
        "        downloads_url=repo_data.get(\"downloads_url\", \"\"),\n",
        "        issues_url=repo_data.get(\"issues_url\", \"\"),\n",
        "        pulls_url=repo_data.get(\"pulls_url\", \"\"),\n",
        "        milestones_url=repo_data.get(\"milestones_url\", \"\"),\n",
        "        notifications_url=repo_data.get(\"notifications_url\", \"\"),\n",
        "        labels_url=repo_data.get(\"labels_url\", \"\"),\n",
        "        releases_url=repo_data.get(\"releases_url\", \"\"),\n",
        "        deployments_url=repo_data.get(\"deployments_url\", \"\"),\n",
        "        created_at=repo_data.get(\"created_at\", \"\"),\n",
        "        updated_at=repo_data.get(\"updated_at\", \"\"),\n",
        "        pushed_at=repo_data.get(\"pushed_at\", \"\"),\n",
        "        git_url=repo_data.get(\"git_url\", \"\"),\n",
        "        ssh_url=repo_data.get(\"ssh_url\", \"\"),\n",
        "        clone_url=repo_data.get(\"clone_url\", \"\"),\n",
        "        svn_url=repo_data.get(\"svn_url\", \"\"),\n",
        "        homepage=repo_data.get(\"homepage\", \"\"),\n",
        "        size=repo_data.get(\"size\", 0),\n",
        "        stargazers_count=repo_data.get(\"stargazers_count\", 0),\n",
        "        watchers_count=repo_data.get(\"watchers_count\", 0),\n",
        "        language=repo_data.get(\"language\", \"\"),\n",
        "        has_issues=repo_data.get(\"has_issues\", False),\n",
        "        has_projects=repo_data.get(\"has_projects\", False),\n",
        "        has_downloads=repo_data.get(\"has_downloads\", False),\n",
        "        has_wiki=repo_data.get(\"has_wiki\", False),\n",
        "        has_pages=repo_data.get(\"has_pages\", False),\n",
        "        has_discussions=repo_data.get(\"has_discussions\", False),\n",
        "        forks_count=repo_data.get(\"forks_count\", 0),\n",
        "        mirror_url=repo_data.get(\"mirror_url\", None),\n",
        "        archived=repo_data.get(\"archived\", False),\n",
        "        disabled=repo_data.get(\"disabled\", False),\n",
        "        open_issues_count=repo_data.get(\"open_issues_count\", 0),\n",
        "        license=license_info,\n",
        "        allow_forking=repo_data.get(\"allow_forking\", False),\n",
        "        is_template=repo_data.get(\"is_template\", False),\n",
        "        web_commit_signoff_required=repo_data.get(\"web_commit_signoff_required\", False),\n",
        "        topics=repo_data.get(\"topics\", []),\n",
        "        visibility=repo_data.get(\"visibility\", \"\"),\n",
        "        forks=repo_data.get(\"forks\", 0),\n",
        "        open_issues=repo_data.get(\"open_issues\", 0),\n",
        "        watchers=repo_data.get(\"watchers\", 0),\n",
        "        default_branch=repo_data.get(\"default_branch\", \"\"),\n",
        "        temp_clone_token=repo_data.get(\"temp_clone_token\", None),\n",
        "        network_count=repo_data.get(\"network_count\", 0),\n",
        "        subscribers_count=repo_data.get(\"subscribers_count\", 0),\n",
        "        contributors=contributors,\n",
        "    )\n",
        "\n",
        "\n",
        "# Fetch repository metadata from GitHub API\n",
        "\n",
        "\n",
        "async def _fetch_repository_metadata(\n",
        "    session: aiohttp.ClientSession, url: str\n",
        ") -> dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Fetch repository metadata from GitHub API.\n",
        "\n",
        "    Args:\n",
        "        session (aiohttp.ClientSession): The aiohttp session to use for the request.\n",
        "        url (str): The API URL for the repository metadata.\n",
        "\n",
        "    Returns:\n",
        "        dict: The JSON response from the GitHub API containing the repository metadata.\n",
        "    \"\"\"\n",
        "    async with session.get(url) as response:\n",
        "        response.raise_for_status()\n",
        "        return await response.json()\n",
        "\n",
        "\n",
        "# Fetch contributors from GitHub API\n",
        "\n",
        "\n",
        "async def _fetch_contributors(\n",
        "    session: aiohttp.ClientSession, url: str\n",
        ") -> List[Contributor]:\n",
        "    \"\"\"\n",
        "    Fetch the list of contributors from the GitHub API.\n",
        "\n",
        "    Args:\n",
        "        session (aiohttp.ClientSession): The aiohttp session to use for the request.\n",
        "        url (str): The API URL for the contributors.\n",
        "\n",
        "    Returns:\n",
        "        List[Contributor]: A list of Contributor objects containing contributor data.\n",
        "    \"\"\"\n",
        "    async with session.get(url) as response:\n",
        "        response.raise_for_status()\n",
        "        contributors_data = await response.json()\n",
        "        return [\n",
        "            Contributor(\n",
        "                name=contributor.get(\"login\", \"\"),\n",
        "                profile_url=contributor.get(\"html_url\", \"\"),\n",
        "                avatar_url=contributor.get(\"avatar_url\", \"\"),\n",
        "                contributions=str(contributor.get(\"contributions\", \"\")),\n",
        "            )\n",
        "            for contributor in contributors_data\n",
        "        ]\n",
        "\n",
        "\n",
        "# Fetch and parse repository metadata including contributors\n",
        "\n",
        "\n",
        "async def fetch_git_repository_metadata(\n",
        "    session: aiohttp.ClientSession, repository_url: str\n",
        ") -> Optional[RepositoryMetadata]:\n",
        "    \"\"\"\n",
        "    Fetch and parse repository metadata from GitHub, including contributors.\n",
        "\n",
        "    Args:\n",
        "        session (aiohttp.ClientSession): The aiohttp session to use for the request.\n",
        "        repository_url (str): The URL of the GitHub repository.\n",
        "\n",
        "    Returns:\n",
        "        Optional[RepositoryMetadata]: A RepositoryMetadata object with the repository data.\n",
        "    \"\"\"\n",
        "    api_url = repository_url.replace(\n",
        "        \"https://github.com/\", \"https://api.github.com/repos/\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        metadata = await _fetch_repository_metadata(session, api_url)\n",
        "        contributors_url = metadata.get(\"contributors_url\", \"\")\n",
        "        contributors = (\n",
        "            await _fetch_contributors(session, contributors_url)\n",
        "            if contributors_url\n",
        "            else []\n",
        "        )\n",
        "        return _parse_repository_metadata(metadata, contributors) if metadata else None\n",
        "    except aiohttp.ClientError as exc:\n",
        "        print(f\"Client error while fetching repository metadata: {exc}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Print metadata in a formatted table\n",
        "\n",
        "\n",
        "def print_metadata(metadata: RepositoryMetadata):\n",
        "    \"\"\"\n",
        "    Print the repository metadata and contributors in a formatted table.\n",
        "\n",
        "    Args:\n",
        "        metadata (RepositoryMetadata): The metadata to print.\n",
        "    \"\"\"\n",
        "    table_metadata = PrettyTable()\n",
        "    table_metadata.field_names = [\"Attribute\", \"Value\"]\n",
        "\n",
        "    for field in metadata.__dataclass_fields__:\n",
        "        value = getattr(metadata, field)\n",
        "        if isinstance(value, dict):\n",
        "            value = json.dumps(value, indent=2)\n",
        "        elif isinstance(value, list):\n",
        "            value = \", \".join(str(item) for item in value)\n",
        "        table_metadata.add_row([field, value])\n",
        "\n",
        "    print(table_metadata)\n",
        "\n",
        "    if metadata.contributors:\n",
        "        contributors_table = PrettyTable()\n",
        "        contributors_table.field_names = [\n",
        "            \"Contributor Name\",\n",
        "            \"Profile URL\",\n",
        "            \"Avatar URL\",\n",
        "            \"No of Contributions\",\n",
        "        ]\n",
        "        for contributor in metadata.contributors:\n",
        "            contributors_table.add_row(\n",
        "                [\n",
        "                    contributor.name,\n",
        "                    contributor.profile_url,\n",
        "                    contributor.avatar_url,\n",
        "                    contributor.contributions,\n",
        "                ]\n",
        "            )\n",
        "        print(contributors_table)\n",
        "\n",
        "\n",
        "# Main function to fetch and display repository metadata\n",
        "\n",
        "\n",
        "async def main(repository_url: str):\n",
        "    \"\"\"\n",
        "    Main function to fetch and display repository metadata.\n",
        "\n",
        "    Args:\n",
        "        repository_url (str): The URL of the GitHub repository to fetch metadata for.\n",
        "    \"\"\"\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        metadata = await fetch_git_repository_metadata(session, repository_url)\n",
        "        if metadata:\n",
        "            print_metadata(metadata)\n",
        "        return metadata\n",
        "\n",
        "\n",
        "# Fetch and display repository metadata\n",
        "metadata = asyncio.run(main(repository_url))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmzUDoeh84k-"
      },
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Folder Structure\n",
        "\n",
        "This section contains functions to print the folder structure of a cloned GitHub repository and to clone a repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi1eeG1v1yIE",
        "outputId": "4f3f9cd2-9bf4-44c4-b954-8377b230fdf7"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import List, Optional\n",
        "\n",
        "\n",
        "def print_folder_structure(\n",
        "    dir_path: Path,\n",
        "    level: int = -1,\n",
        "    limit_to_directories: bool = False,\n",
        "    length_limit: int = 1000,\n",
        "    file_folder_to_be_ignored: List[str] = None,\n",
        ") -> List[str]:\n",
        "    \"\"\"\n",
        "    Generate a visual tree structure of the directory contents.\n",
        "\n",
        "    Parameters:\n",
        "    dir_path (Path): The root directory to start the tree from.\n",
        "    level (int, optional): The depth of recursion. Defaults to -1 (no limit).\n",
        "    limit_to_directories (bool, optional): If True, only directories are listed. Defaults to False.\n",
        "    length_limit (int, optional): Limits the number of lines output. Defaults to 1000.\n",
        "    file_folder_to_be_ignored (List[str], optional): A list of directory or file names to ignore. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "    List[str]: A list of strings representing the directory tree structure.\n",
        "    \"\"\"\n",
        "    space = \"    \"\n",
        "    branch = \"│   \"\n",
        "    tee = \"├── \"\n",
        "    last = \"└── \"\n",
        "    dir_path = Path(dir_path)  # Ensure dir_path is a Path object\n",
        "    files = 0\n",
        "    directories = 0\n",
        "    output = []\n",
        "\n",
        "    if file_folder_to_be_ignored is None:\n",
        "        file_folder_to_be_ignored = []\n",
        "\n",
        "    def inner(dir_path: Path, prefix: str = \"\", level: int = -1):\n",
        "        nonlocal files, directories\n",
        "        if level == 0:\n",
        "            return  # Stop recursion if level is 0\n",
        "        if limit_to_directories:\n",
        "            contents = [\n",
        "                d\n",
        "                for d in dir_path.iterdir()\n",
        "                if d.is_dir() and d.name not in file_folder_to_be_ignored\n",
        "            ]\n",
        "        else:\n",
        "            contents = [\n",
        "                d for d in dir_path.iterdir() if d.name not in file_folder_to_be_ignored\n",
        "            ]\n",
        "        pointers = [tee] * (len(contents) - 1) + [last]\n",
        "        for pointer, path in zip(pointers, contents):\n",
        "            if path.is_dir():\n",
        "                output.append(prefix + pointer + path.name + \"/\")\n",
        "                directories += 1\n",
        "                extension = branch if pointer == tee else space\n",
        "                inner(path, prefix=prefix + extension, level=level - 1)\n",
        "            elif not limit_to_directories:\n",
        "                output.append(prefix + pointer + path.name)\n",
        "                files += 1\n",
        "\n",
        "    # Add the root directory name\n",
        "    output.append(dir_path.name + \"/\")\n",
        "    # Create an iterator from the inner function\n",
        "    inner(dir_path, level=level)\n",
        "    # Limit the output by length_limit\n",
        "    if len(output) > length_limit:\n",
        "        output = output[:length_limit]\n",
        "        output.append(f\"... length_limit, {length_limit}, reached, counted:\")\n",
        "    # Add the summary of directories and files\n",
        "    output.append(\n",
        "        f\"\\n{directories} directories\" + (f\", {files} files\" if files else \"\")\n",
        "    )\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "if cloned_repo_path:\n",
        "    # Print the folder structure\n",
        "    folder_structure = print_folder_structure(\n",
        "        dir_path=Path(cloned_repo_path),\n",
        "        file_folder_to_be_ignored=ignore_list_folder_structure,\n",
        "    )\n",
        "    folder_structure_str = \"\\n\".join(folder_structure)\n",
        "    folder_structure_markdown = (\n",
        "        \"# Folder Structure\\n\" + \"```sh\\n\" + folder_structure_str + \"\\n\" + \"```\"\n",
        "    )\n",
        "    print(folder_structure_markdown)\n",
        "else:\n",
        "    print(\"Repository cloning failed or was skipped.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Model setup for Ollama\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the model selection\n",
        "model = {\"model_client\": OllamaClient(), \"model_kwargs\": {\"model\": \"llama3.1:8b\"}}\n",
        "\n",
        "\n",
        "def get_description_data(description):\n",
        "    \"\"\"\n",
        "    Retrieve data from the description object if it has a `data` attribute.\n",
        "\n",
        "    Parameters:\n",
        "    description (object): The object from which to retrieve the data. This can be any object that may or may not have a `data` attribute.\n",
        "\n",
        "    Returns:\n",
        "    str: The data from the `description` object if it exists, otherwise the original description.\n",
        "    \"\"\"\n",
        "    if hasattr(description, \"data\"):\n",
        "        return description.data\n",
        "    return description\n",
        "\n",
        "\n",
        "def is_empty_or_error(description):\n",
        "    \"\"\"\n",
        "    Check if the description is empty or contains an error message.\n",
        "\n",
        "    Parameters:\n",
        "    description (str): The description string to check for emptiness or error messages.\n",
        "\n",
        "    Returns:\n",
        "    bool: True if the description is empty or contains an HTTP 401 error message, otherwise False.\n",
        "    \"\"\"\n",
        "    description_str = (\n",
        "        get_description_data(description).strip()\n",
        "        if isinstance(description, str)\n",
        "        else \"\"\n",
        "    )\n",
        "    return not description_str or \"HTTP error 401\" in description_str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sJvgNP6883Q"
      },
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Summary Generation\n",
        "\n",
        "This section contains code to generate summaries for files in a GitHub repository using a summarization model. The notebook includes functions to:\n",
        "\n",
        "- Generate summaries for all relevant files in a repository.\n",
        "- Handle errors and save results to an Excel file.\n",
        "- Provide a mechanism to retry summarization for files that encountered errors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightrag.core.generator import Generator\n",
        "from lightrag.core.component import Component\n",
        "from lightrag.components.model_client import OllamaClient\n",
        "\n",
        "summary_template = r\"\"\"<SYS>\n",
        "You are a summarization assistant specialized in coding files.\n",
        "</SYS>\n",
        "Please summarize the following code:\n",
        "{{input_str}}\n",
        "Summary:\"\"\"\n",
        "\n",
        "\n",
        "class SummaryQA(Component):\n",
        "    \"\"\"\n",
        "    A component that uses a summarization model to generate summaries for code.\n",
        "\n",
        "    Parameters:\n",
        "    model_client (OllamaClient): The model client to interact with the summarization model.\n",
        "    model_kwargs (dict): Additional keyword arguments for the model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_client: OllamaClient, model_kwargs: dict):  # type: ignore\n",
        "        super().__init__()\n",
        "        self.generator = Generator(\n",
        "            model_client=model_client,\n",
        "            model_kwargs=model_kwargs,\n",
        "            template=summary_template,\n",
        "        )\n",
        "\n",
        "    def call(self, input: str) -> str:\n",
        "        \"\"\"\n",
        "        Generate a summary for the provided code using the model.\n",
        "\n",
        "        Parameters:\n",
        "        input (str): The code to be summarized.\n",
        "\n",
        "        Returns:\n",
        "        str: The generated summary.\n",
        "        \"\"\"\n",
        "        return self.generator.call({\"input_str\": input})\n",
        "\n",
        "    async def acall(self, input: str) -> str:\n",
        "        \"\"\"\n",
        "        Asynchronously generate a summary for the provided code using the model.\n",
        "\n",
        "        Parameters:\n",
        "        input (str): The code to be summarized.\n",
        "\n",
        "        Returns:\n",
        "        str: The generated summary.\n",
        "        \"\"\"\n",
        "        return await self.generator.acall({\"input_str\": input})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbLjLLCN2p32",
        "outputId": "1033da6c-5221-4cdd-8f02-ce1dbb19a048"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "from prettytable import PrettyTable\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def generate_summary(\n",
        "    path: Path,\n",
        "    ignore_list: List[str],\n",
        "    summary_component: SummaryQA,\n",
        "    ignore_extensions: List[str],\n",
        ") -> List[Dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Generate a summary of files in the given path using the summarization model.\n",
        "\n",
        "    Parameters:\n",
        "    path (Path): The root directory to start scanning for files.\n",
        "    ignore_list (List[str]): A list of directory or file names to ignore.\n",
        "    summary_component (SummaryQA): The summarization component to use for generating summaries.\n",
        "    ignore_extensions (List[str]): A list of file extensions to ignore.\n",
        "\n",
        "    Returns:\n",
        "    List[Dict[str, str]]: A list of dictionaries where each dictionary contains the file path and its summary.\n",
        "    \"\"\"\n",
        "    summary = []\n",
        "    files_to_process = []\n",
        "\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        # Get relative path for the current directory\n",
        "        relative_root = os.path.relpath(root, path)\n",
        "\n",
        "        # Check if the directory should be ignored\n",
        "        if any(ignored in relative_root.split(os.sep) for ignored in ignore_list):\n",
        "            continue\n",
        "\n",
        "        if relative_root == \".\":\n",
        "            summary.append({\"file\": \"Modules\", \"description\": \".\"})\n",
        "        else:\n",
        "            summary.append({\"file\": relative_root, \"description\": \"Not a File\"})\n",
        "\n",
        "        # List files in the current directory\n",
        "        for file in files:\n",
        "            file_path = Path(root) / file\n",
        "\n",
        "            # Check if the file should be ignored\n",
        "            if any(ignored in file_path.parts for ignored in ignore_list):\n",
        "                continue\n",
        "\n",
        "            # Check if the file has an extension that should be skipped\n",
        "            if file_path.suffix.lower() in ignore_extensions:\n",
        "                continue\n",
        "\n",
        "            files_to_process.append(file_path)\n",
        "\n",
        "    # Use tqdm to display progress\n",
        "    pbar = tqdm(files_to_process, unit=\"file\")\n",
        "    for file_path in pbar:\n",
        "        # Update the description dynamically\n",
        "        pbar.set_description(f\"Processing files - {file_path}\")\n",
        "        try:\n",
        "            # Read file content\n",
        "            with open(file_path, \"r\") as f:\n",
        "                file_content = f.read()\n",
        "\n",
        "            # Generate summary using the model\n",
        "            summary_text = summary_component.call(file_content)\n",
        "            summary.append({\"file\": file_path, \"description\": summary_text})\n",
        "        except Exception as e:\n",
        "            summary.append(\n",
        "                {\"file\": file_path, \"description\": f\"Error processing file: {str(e)}\"}\n",
        "            )\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "summary_qa = SummaryQA(**model)\n",
        "\n",
        "if cloned_repo_path:\n",
        "    path = Path(cloned_repo_path)\n",
        "    if not path.is_dir():\n",
        "        print(f\"The path {path} is not a directory.\")\n",
        "    summary = generate_summary(\n",
        "        path,\n",
        "        ignore_list=ignore_list_folder_structure,\n",
        "        summary_component=summary_qa,\n",
        "        ignore_extensions=ignore_list_extensions,\n",
        "    )\n",
        "    table_summary = PrettyTable()\n",
        "    table_summary.field_names = [\"File\", \"Description\"]\n",
        "\n",
        "    for item in summary:\n",
        "        table_summary.add_row([item[\"file\"], item[\"description\"]])\n",
        "\n",
        "    print(table_summary)\n",
        "else:\n",
        "    print(\"Repository cloning failed or was skipped.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "#### Save Summary to Excel\n",
        "\n",
        "This section converts the summary data into an Excel file format for further analysis or record-keeping.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs3UaeTl6mi4",
        "outputId": "b3bc4fbd-db91-4cdd-b9f1-45687e255284"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "\n",
        "def save_summary_to_excel_and_print_table(\n",
        "    summary: List[Dict[str, str]], cloned_repo_path: str\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Save the summary data to an Excel file and print it in a formatted table.\n",
        "\n",
        "    Parameters:\n",
        "    summary (List[Dict[str, str]]): A list of dictionaries containing file paths and their summaries.\n",
        "    cloned_repo_path (str): The path of the cloned repository to be used for naming the Excel file.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    if summary:\n",
        "        # Initialize PrettyTable\n",
        "        table_summary = PrettyTable()\n",
        "        table_summary.field_names = [\"File\", \"Description\"]\n",
        "\n",
        "        # Create a list to hold data for the DataFrame\n",
        "        summary_data_for_excel = []\n",
        "\n",
        "        for item in summary:\n",
        "            # Retrieve description data\n",
        "            description_data = get_description_data(item[\"description\"])\n",
        "            # Add data to PrettyTable\n",
        "            table_summary.add_row([item[\"file\"], description_data])\n",
        "            # Add data to the list for the DataFrame\n",
        "            summary_data_for_excel.append(\n",
        "                {\"File\": item[\"file\"], \"Description\": description_data}\n",
        "            )\n",
        "\n",
        "        # Print the PrettyTable\n",
        "        print(table_summary)\n",
        "\n",
        "        # Convert the list to a DataFrame\n",
        "        summary_df = pd.DataFrame(summary_data_for_excel)\n",
        "\n",
        "        # Define the path and name for the Excel file\n",
        "        excel_path = f\"output/{metadata.name}_summary.xlsx\"\n",
        "\n",
        "        # Save DataFrame to an Excel file\n",
        "        summary_df.to_excel(excel_path, index=False, engine=\"openpyxl\")\n",
        "        print(f\"Summary saved to {excel_path}\")\n",
        "    else:\n",
        "        print(\"No summary data available to save or print.\")\n",
        "\n",
        "\n",
        "# Assuming `summary` and `cloned_repo_path` are defined earlier in the code\n",
        "save_summary_to_excel_and_print_table(summary, cloned_repo_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "#### Retry Summarization for Errors\n",
        "\n",
        "This section handles cases where summaries couldn't be generated initially, either due to errors or blank descriptions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6JW55tv6vY7",
        "outputId": "ed50f645-1947-4614-d2e1-725761826603"
      },
      "outputs": [],
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "# Check if there is any summary data available\n",
        "if summary:\n",
        "\n",
        "    # Variable to store rows with empty or error descriptions before adding to the table\n",
        "    blank_error_summary = []\n",
        "\n",
        "    # Iterate over each item in the summary\n",
        "    for item in summary:\n",
        "\n",
        "        # Retrieve the description data from the item\n",
        "        description_data = get_description_data(item[\"description\"])\n",
        "\n",
        "        # Check if the description is empty or contains an error\n",
        "        if is_empty_or_error(description_data):\n",
        "\n",
        "            # Save the row data (file path and description) into a variable\n",
        "            row = [item[\"file\"], description_data]\n",
        "\n",
        "            # Append the row to the list of blank or error summaries\n",
        "            blank_error_summary.append(row)\n",
        "\n",
        "    # Initialize PrettyTable to format the output\n",
        "    retry_table = PrettyTable()\n",
        "\n",
        "    # Set the field names (column headers) for the table\n",
        "    retry_table.field_names = [\"File\", \"Description\"]\n",
        "\n",
        "    # Add the saved rows (those with blank or error descriptions) to the table\n",
        "    for row in blank_error_summary:\n",
        "\n",
        "        retry_table.add_row(row)\n",
        "\n",
        "    # Print the PrettyTable with the rows that have blank or error descriptions\n",
        "    print(retry_table)\n",
        "\n",
        "else:\n",
        "    # Print a message if no summary data is available\n",
        "    print(\"NO SUMMARY DATA AVAILABLE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "#### Generate Summary for Specific Files\n",
        "\n",
        "This section provides functionality to manually generate or update summaries for individual files based on user input.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJs-AJ1T51yD"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict\n",
        "from pathlib import Path\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "\n",
        "def generate_summary_for_file(\n",
        "    file_path: Path, qa_component: SummaryQA, existing_summaries: List[Dict[str, str]]\n",
        ") -> List[Dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Generate or update a summary for a single file using the model.\n",
        "\n",
        "    Args:\n",
        "        file_path (Path): The path to the file to be summarized.\n",
        "        qa_component (SummaryQA): The component that generates the summary.\n",
        "        existing_summaries (List[Dict[str, str]]): A list of existing summaries to update.\n",
        "\n",
        "    Returns:\n",
        "        List[Dict[str, str]]: The updated list of summaries including the new or updated summary for the file.\n",
        "    \"\"\"\n",
        "    file_name = file_path.name\n",
        "    updated = False\n",
        "\n",
        "    # Check if the file summary already exists in the existing_summaries list\n",
        "    for summary in existing_summaries:\n",
        "        if summary[\"file\"] == file_name:\n",
        "            updated = True  # Mark as updated if the summary already exists\n",
        "            break\n",
        "\n",
        "    # If no summary exists for the file, add a new entry with an empty description\n",
        "    if not updated:\n",
        "        existing_summaries.append({\"file\": file_name, \"description\": \"\"})\n",
        "\n",
        "    try:\n",
        "        # Read the content of the file\n",
        "        with open(file_path, \"r\") as f:\n",
        "            file_content = f.read()\n",
        "\n",
        "        # Generate a summary for the file content using the qa_component\n",
        "        summary_text = qa_component.call(file_content)\n",
        "\n",
        "        # Update the description in the existing_summaries list\n",
        "        for summary in existing_summaries:\n",
        "            if summary[\"file\"] == file_name:\n",
        "                summary[\"description\"] = summary_text\n",
        "                break\n",
        "    except Exception as e:\n",
        "        # Handle exceptions and update the summary with an error message\n",
        "        for summary in existing_summaries:\n",
        "            if summary[\"file\"] == file_name:\n",
        "                summary[\"description\"] = f\"Error processing file {file_path}: {str(e)}\"\n",
        "                break\n",
        "\n",
        "    return existing_summaries\n",
        "\n",
        "\n",
        "if blank_error_summary:\n",
        "    # Initialize an empty list to store the summaries\n",
        "    summaries = []\n",
        "\n",
        "    # Prompt the user for a file path\n",
        "    user_input = input(\"Please enter the path to the file you want to summarize: \")\n",
        "    file_path = Path(user_input)\n",
        "\n",
        "    if file_path.is_file():\n",
        "        # Generate or update the summary for the specified file\n",
        "        summaries = generate_summary_for_file(file_path, summary_qa, summaries)\n",
        "\n",
        "        # Print the summary using PrettyTable\n",
        "        table_summary = PrettyTable()\n",
        "        table_summary.field_names = [\"File\", \"Description\"]\n",
        "\n",
        "        # Add each summary to the PrettyTable\n",
        "        for summary in summaries:\n",
        "            table_summary.add_row([summary[\"file\"], summary[\"description\"]])\n",
        "\n",
        "        print(table_summary)\n",
        "    else:\n",
        "        # If the path is not a valid file, print an error message\n",
        "        print(f\"The path {file_path} is not a valid file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "#### Combine Summaries\n",
        "\n",
        "This section combines all generated summaries into a single summary string, filtering out unnecessary or erroneous data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVtFXb5V6vY8",
        "outputId": "524e4270-b947-4a58-aeac-029d81768bd9"
      },
      "outputs": [],
      "source": [
        "if summary:\n",
        "    # Combine summaries, ignoring \"Not a File\" or error messages\n",
        "    combined_summary = \" \".join(\n",
        "        [\n",
        "            get_description_data(item[\"description\"])\n",
        "            for item in summary\n",
        "            if get_description_data(item[\"description\"])\n",
        "            and get_description_data(item[\"description\"]) != \"Not a File\"\n",
        "            and get_description_data(item[\"description\"]) != \".\"\n",
        "            and not get_description_data(item[\"description\"]).startswith(\n",
        "                \"HTTP error 401\"\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    print(combined_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Header\n",
        "\n",
        "This section contains code to generate\n",
        "\n",
        "- Project image and name.\n",
        "- GitHub status badges.\n",
        "- Language and framework badges.\n",
        "- Combining all elements for the project header.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "#### Project Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Select the project type:\n",
            "1. Ecommerce\n",
            "2. Banking\n",
            "3. School\n",
            "4. Education\n",
            "5. Work\n",
            "6. Healthcare\n",
            "7. Real_estate\n",
            "8. Travel\n",
            "9. Social_media\n",
            "10. Fitness\n",
            "11. News\n",
            "12. Entertainment\n",
            "13. Food_delivery\n",
            "14. Finance\n",
            "15. Transportation\n",
            "16. Hospitality\n",
            "17. Music\n",
            "18. Gaming\n",
            "19. Environment\n",
            "20. Nonprofit\n",
            "21. Photography\n",
            "22. Custom\n",
            "23. None\n",
            "\n",
            "<p align=\"center\">\n",
            "    <img src=\"https://img.icons8.com/nolan/512/1A6DFF/C822FF/shopping-basket-2.png\" width=\"200\" style=\"border-radius: 20px;\" />\n",
            "</p>\n",
            "    \n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'Markdown' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(project_image_markdown)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Display the Markdown content (useful in Jupyter notebooks)\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m display(\u001b[43mMarkdown\u001b[49m(project_image_markdown))\n",
            "\u001b[1;31mNameError\u001b[0m: name 'Markdown' is not defined"
          ]
        }
      ],
      "source": [
        "def get_project_icon():\n",
        "    \"\"\"\n",
        "    Prompt the user to select a project type or enter a custom link/path for the project icon.\n",
        "\n",
        "    Returns:\n",
        "        str: The URL or path of the selected or custom project icon.\n",
        "             Returns None if 'None' is selected or if the input is invalid.\n",
        "    \"\"\"\n",
        "    # Display project type options to the user\n",
        "    print(\"Select the project type:\")\n",
        "    for i, key in enumerate(project_icons.keys(), start=1):\n",
        "        print(f\"{i}. {key.capitalize()}\")\n",
        "    print(f\"{len(project_icons) + 1}. Custom\")\n",
        "    print(f\"{len(project_icons) + 2}. None\")\n",
        "\n",
        "    # Prompt the user to select an option\n",
        "    choice = input(\"Enter the number corresponding to the project type: \")\n",
        "    return choice\n",
        "\n",
        "\n",
        "# Get the icon URL or custom path\n",
        "choice = get_project_icon()\n",
        "\n",
        "if choice.isdigit():  # Check if the input is a digit\n",
        "    choice = int(choice)\n",
        "\n",
        "    # Check if the choice corresponds to a predefined project type\n",
        "    if 1 <= choice <= len(project_icons):\n",
        "        selected_type = list(project_icons.keys())[choice - 1]\n",
        "        icon_url = project_icons[selected_type][\"icon\"]  # Get the icon URL\n",
        "\n",
        "    # Check if the choice is 'Custom'\n",
        "    elif choice == len(project_icons) + 1:\n",
        "        custom_link = input(\"Enter the custom link/path: \")\n",
        "        icon_url = custom_link\n",
        "    else:\n",
        "        # If input is invalid, display an error message and return None\n",
        "        print(\"Invalid choice. Please try again.\")\n",
        "        icon_url = None\n",
        "\n",
        "if icon_url:\n",
        "    # Generate the Markdown for displaying the project icon\n",
        "    project_image_markdown = f\"\"\"\n",
        "<p align=\"center\">\n",
        "    <img src=\"{icon_url}\" width=\"200\" style=\"border-radius: 20px;\" />\n",
        "</p>\n",
        "    \"\"\"\n",
        "else:\n",
        "    # Set an empty Markdown string if no icon is selected\n",
        "    project_image_markdown = \"\"\n",
        "\n",
        "# Print the Markdown content (for debugging or display in a non-notebook environment)\n",
        "print(project_image_markdown)\n",
        "\n",
        "# Display the Markdown content (useful in Jupyter notebooks)\n",
        "display(Markdown(project_image_markdown))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "#### Project Name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "project_name_markdown = f\"\"\"\n",
        "<p align=\"center\">\n",
        "    <h1>{metadata.name}</h1>\n",
        "</p>\n",
        "\"\"\"\n",
        "print(project_name_markdown)\n",
        "display(Markdown(project_name_markdown))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "#### GitHub Status Badges\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_github_badge_urls(github_repo_link, badges):\n",
        "    \"\"\"Update GitHub status badge URLs based on the selected badges.\n",
        "\n",
        "    Args:\n",
        "        github_repo_link (str): The GitHub repository link.\n",
        "        badges (list): A list of badge identifiers to include.\n",
        "\n",
        "    Returns:\n",
        "        str: A string containing the HTML code for the selected badges.\n",
        "    \"\"\"\n",
        "    # Extract the owner and repository name from the GitHub link\n",
        "    repo_path = github_repo_link.rstrip(\"/\").replace(\"https://github.com/\", \"\")\n",
        "\n",
        "    # Define the badge URLs\n",
        "    badge_urls = {\n",
        "        \"license\": f\"https://img.shields.io/github/license/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"last-commit\": f\"https://img.shields.io/github/last-commit/{repo_path}?style=flat&logo=git&logoColor=white&color=0080ff\",\n",
        "        \"repo-top-language\": f\"https://img.shields.io/github/languages/top/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"repo-language-count\": f\"https://img.shields.io/github/languages/count/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"build-status\": f\"https://img.shields.io/github/actions/workflow/status/{repo_path}/build.yml?branch=main&style=flat&color=0080ff\",\n",
        "        \"open-issues\": f\"https://img.shields.io/github/issues/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"forks\": f\"https://img.shields.io/github/forks/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"stars\": f\"https://img.shields.io/github/stars/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"pull-requests\": f\"https://img.shields.io/github/issues-pr/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"contributors\": f\"https://img.shields.io/github/contributors/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"commit-activity\": f\"https://img.shields.io/github/commit-activity/m/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"code-size\": f\"https://img.shields.io/github/languages/code-size/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"repo-size\": f\"https://img.shields.io/github/repo-size/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"downloads\": f\"https://img.shields.io/github/downloads/{repo_path}/total?style=flat&color=0080ff\",\n",
        "        \"sponsors\": f\"https://img.shields.io/github/sponsors/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"release-version\": f\"https://img.shields.io/github/v/release/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"coverage\": f\"https://img.shields.io/codecov/c/github/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"code-quality\": f\"https://img.shields.io/codeclimate/quality/a/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"dependencies\": f\"https://img.shields.io/david/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"dev-dependencies\": f\"https://img.shields.io/david/dev/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"security\": f\"https://img.shields.io/snyk/vulnerabilities/github/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"performance\": f\"https://img.shields.io/website?style=flat&color=0080ff&url=https%3A%2F%2Fexample.com\",\n",
        "        \"activity\": f\"https://img.shields.io/github/commit-activity/y/{repo_path}?style=flat&color=0080ff\",\n",
        "        \"documentation\": f\"https://img.shields.io/docsify/docs?style=flat&color=0080ff\",\n",
        "        \"version\": f\"https://img.shields.io/github/v/tag/{repo_path}?style=flat&color=0080ff\",\n",
        "    }\n",
        "\n",
        "    # Create the HTML string based on the selected badges\n",
        "    badges_html = \"\\n\".join(\n",
        "        f'  <img src=\"{badge_urls[badge]}\" alt=\"{badge}\">'\n",
        "        for badge in badges\n",
        "        if badge in badge_urls\n",
        "    )\n",
        "\n",
        "    # Generate the final HTML template\n",
        "    html_template = f\"\"\"\n",
        "<p align=\"center\">\n",
        "{badges_html}\n",
        "</p>\n",
        "    \"\"\"\n",
        "\n",
        "    return html_template\n",
        "\n",
        "\n",
        "# Define the selected badges\n",
        "selected_badges = [\n",
        "    \"license\",\n",
        "    \"last-commit\",\n",
        "    \"repo-top-language\",\n",
        "    \"repo-language-count\",\n",
        "    \"build-status\",\n",
        "    \"open-issues\",\n",
        "    \"forks\",\n",
        "    \"stars\",\n",
        "    \"pull-requests\",\n",
        "    \"contributors\",\n",
        "    \"commit-activity\",\n",
        "    \"code-size\",\n",
        "    \"repo-size\",\n",
        "    \"downloads\",\n",
        "    \"sponsors\",\n",
        "    \"release-version\",\n",
        "    \"coverage\",\n",
        "    \"code-quality\",\n",
        "    \"dependencies\",\n",
        "    \"dev-dependencies\",\n",
        "    \"security\",\n",
        "    \"performance\",\n",
        "    \"activity\",\n",
        "    \"documentation\",\n",
        "    \"version\",\n",
        "]\n",
        "\n",
        "# Update the GitHub badge URLs\n",
        "github_badge_markdown = update_github_badge_urls(repository_url, selected_badges)\n",
        "\n",
        "# Print and display the GitHub badge markdown\n",
        "print(github_badge_markdown)\n",
        "display(Markdown(github_badge_markdown))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "#### Language and Framework Badges\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "import os\n",
        "\n",
        "languages_found = set()\n",
        "frameworks_found = set()\n",
        "tools_found = set()\n",
        "\n",
        "\n",
        "def identify_project(root_folder):\n",
        "    \"\"\"\n",
        "    Identify languages, frameworks, and tools used in the project based on file extensions and configuration files.\n",
        "\n",
        "    Parameters:\n",
        "    root_folder (str): The root directory of the project to scan.\n",
        "\n",
        "    Updates:\n",
        "    - languages_found: A set of languages identified from file extensions.\n",
        "    - frameworks_found: A set of frameworks identified from configuration files.\n",
        "    - tools_found: A set of tools identified from configuration files.\n",
        "    \"\"\"\n",
        "    for root, _, files in os.walk(root_folder):\n",
        "        for file in files:\n",
        "            ext = os.path.splitext(file)[1]\n",
        "            if ext in [e for exts in extensions.values() for e in exts]:\n",
        "                for language, exts in extensions.items():\n",
        "                    if ext in exts:\n",
        "                        languages_found.add(language)\n",
        "            for framework, config_files in frameworks_extensions.items():\n",
        "                if file in config_files:\n",
        "                    frameworks_found.add(framework)\n",
        "            for tool, config_files in tools_extensions.items():\n",
        "                if file in config_files:\n",
        "                    tools_found.add(tool)\n",
        "\n",
        "    print(\"Languages found:\", \", \".join(languages_found) or \"None\")\n",
        "    print(\"Frameworks found:\", \", \".join(frameworks_found) or \"None\")\n",
        "    print(\"Tools found:\", \", \".join(tools_found) or \"None\")\n",
        "\n",
        "\n",
        "def get_languages_from_github(languages_url):\n",
        "    \"\"\"\n",
        "    Retrieve the list of languages used in the GitHub repository.\n",
        "\n",
        "    Parameters:\n",
        "    languages_url (str): The URL of the GitHub API endpoint to fetch language data.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with languages as keys and their respective sizes as values.\n",
        "    \"\"\"\n",
        "    response = requests.get(languages_url)\n",
        "    response.raise_for_status()  # Raise an error for bad responses\n",
        "    languages = response.json()\n",
        "    return languages\n",
        "\n",
        "\n",
        "def load_shields_data(filename):\n",
        "    \"\"\"\n",
        "    Load shields.io icons data from a JSON file.\n",
        "\n",
        "    Parameters:\n",
        "    filename (str): The path to the JSON file containing shields.io icon data.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with technologies as keys and their badge URLs and other metadata as values.\n",
        "    \"\"\"\n",
        "    with open(filename, \"r\") as file:\n",
        "        return json.load(file)\n",
        "\n",
        "\n",
        "def get_shields_urls(technologies, shields_data):\n",
        "    \"\"\"\n",
        "    Generate URLs for shields.io badges based on the technologies found.\n",
        "\n",
        "    Parameters:\n",
        "    technologies (set): A set of technology names for which badge URLs are to be generated.\n",
        "    shields_data (dict): A dictionary containing badge URLs and metadata for various technologies.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with technology names as keys and their badge URLs as values.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    for tech in technologies:\n",
        "        if tech in shields_data:\n",
        "            url, _ = shields_data[tech]\n",
        "            results[tech] = url.format(\"for-the-badge\")\n",
        "        else:\n",
        "            fallback_url = f\"https://img.shields.io/badge/{tech}-ED8B00?logo={tech}&logoColor=white\"\n",
        "            results[tech] = fallback_url\n",
        "    return results\n",
        "\n",
        "\n",
        "def generate_language_badges(urls_map):\n",
        "    \"\"\"\n",
        "    Generate HTML for language badges.\n",
        "\n",
        "    Parameters:\n",
        "    urls_map (dict): A dictionary with technology names as keys and badge URLs as values.\n",
        "\n",
        "    Returns:\n",
        "    str: HTML string containing the badges.\n",
        "    \"\"\"\n",
        "    badges_html = \"\\n\".join(\n",
        "        f'  <img src=\"{urls_map[language]}\" alt=\"{language}\">'\n",
        "        for language in urls_map.keys()\n",
        "    )\n",
        "\n",
        "    html_template = f\"\"\"\n",
        "<p align=\"center\">\n",
        "{badges_html}\n",
        "</p>\n",
        "    \"\"\"\n",
        "\n",
        "    return html_template\n",
        "\n",
        "\n",
        "if os.path.isdir(cloned_repo_path):\n",
        "    identify_project(cloned_repo_path)\n",
        "    languages_from_github = get_languages_from_github(metadata.languages_url)\n",
        "    for language in languages_from_github.keys():\n",
        "        languages_found.add(language)\n",
        "    # Load shields.io data\n",
        "    shields_data = load_shields_data(\"./shieldsio_icons.json\")\n",
        "\n",
        "    # Combine results and search in shields.io data\n",
        "    combined_results = {\n",
        "        **{lang: None for lang in languages_found},\n",
        "        **{framework: None for framework in frameworks_found},\n",
        "        **{tool: None for tool in tools_found},\n",
        "    }\n",
        "\n",
        "    # Get URLs for combined results\n",
        "    badges_urls_map = get_shields_urls(combined_results.keys(), shields_data)\n",
        "\n",
        "    # Print results\n",
        "    if badges_urls_map:\n",
        "        print(badges_urls_map)\n",
        "        language_badges_markdown = f\"\"\"\n",
        "<p align=\"center\">\n",
        "    <em>Constructed using the following tools and technologies:</em>\n",
        "</p>\n",
        "{generate_language_badges(badges_urls_map)}\n",
        "\"\"\"\n",
        "        print(language_badges_markdown)\n",
        "        display(Markdown(language_badges_markdown))\n",
        "    else:\n",
        "        print(\"No matching languages, frameworks, or tools found in shields.io data\")\n",
        "else:\n",
        "    print(\"Invalid directory path\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "#### Combining all for Header\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine various markdown sections to create the header\n",
        "\n",
        "header_markdown = (\n",
        "    project_image_markdown  # Markdown for the project image\n",
        "    + \"\\n\"\n",
        "    + project_name_markdown  # Markdown for the project name\n",
        "    + \"\\n\"\n",
        "    + github_badge_markdown  # Markdown for GitHub badges\n",
        "    + \"\\n\"\n",
        "    + language_badges_markdown  # Markdown for language badges\n",
        "    + \"\\n\"\n",
        "    + \"\"  # Add an empty string for consistency\n",
        ")\n",
        "\n",
        "# Print the combined markdown header\n",
        "print(header_markdown)\n",
        "\n",
        "# Display the combined markdown header in a Markdown format\n",
        "display(Markdown(header_markdown))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Project Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightrag.core.generator import Generator\n",
        "from lightrag.core.component import Component\n",
        "from lightrag.components.model_client import OllamaClient\n",
        "\n",
        "# Define the template for generating a project overview\n",
        "project_overview_template = r\"\"\"<SYS>\n",
        "You are a summarization assistant specialized in project documentation.\n",
        "</SYS>\n",
        "Based on the provided file summaries:\n",
        "{{input_str}},\n",
        "\n",
        "Generate a concise and descriptive one-paragraph overview of the project, including:\n",
        "1. What the project is about (2 sentences).\n",
        "2. What the project does (more than 3 sentences).\n",
        "3. The technologies used.\n",
        "4. The key features of the project.\n",
        "\n",
        "Don't add predescription and post description in the answer.\n",
        "Summary:\"\"\"\n",
        "\n",
        "\n",
        "class OverviewQA(Component):\n",
        "    \"\"\"\n",
        "    Component for generating a project overview.\n",
        "\n",
        "    This class uses a model to generate a summary of the project based on the provided file summaries.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_client: OllamaClient, model_kwargs: dict):  # type: ignore\n",
        "        \"\"\"\n",
        "        Initialize the OverviewQA component.\n",
        "\n",
        "        Parameters:\n",
        "        model_client (OllamaClient): The client used to interact with the model.\n",
        "        model_kwargs (dict): Additional keyword arguments for the model.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.generator = Generator(\n",
        "            model_client=model_client,\n",
        "            model_kwargs=model_kwargs,\n",
        "            template=project_overview_template,\n",
        "        )\n",
        "\n",
        "    def call(self, summaries: str) -> str:\n",
        "        \"\"\"\n",
        "        Generate a project overview based on file summaries.\n",
        "\n",
        "        Parameters:\n",
        "        summaries (str): The file summaries to use for generating the overview.\n",
        "\n",
        "        Returns:\n",
        "        str: The generated project overview.\n",
        "        \"\"\"\n",
        "        return self.generator.call({\"input_str\": summaries})\n",
        "\n",
        "    async def acall(self, summaries: str) -> str:\n",
        "        \"\"\"\n",
        "        Asynchronous version for generating a project overview.\n",
        "\n",
        "        Parameters:\n",
        "        summaries (str): The file summaries to use for generating the overview.\n",
        "\n",
        "        Returns:\n",
        "        str: The generated project overview.\n",
        "        \"\"\"\n",
        "        return await self.generator.acall({\"input_str\": summaries})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "ZUgI_Ipe6vY8",
        "outputId": "66a0ee1f-534d-438e-aa92-426cc0a14593"
      },
      "outputs": [],
      "source": [
        "def generate_project_overview(\n",
        "    combined_summary: str, overview_component: OverviewQA\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Generate a concise and descriptive overview of the project.\n",
        "\n",
        "    This function uses the OverviewQA component to create a project overview based on the combined summaries of the project files.\n",
        "\n",
        "    Parameters:\n",
        "    combined_summary (str): A string containing the combined summaries of the project files.\n",
        "    overview_component (OverviewQA): The component used to generate the project overview.\n",
        "\n",
        "    Returns:\n",
        "    str: The generated project overview.\n",
        "    \"\"\"\n",
        "    return overview_component.generator.call({\"input_str\": combined_summary})\n",
        "\n",
        "\n",
        "# Initialize OverviewQA component with model configuration\n",
        "overview_qa = OverviewQA(**model)\n",
        "\n",
        "if combined_summary:\n",
        "    # Generate the project overview\n",
        "    project_overview = generate_project_overview(\n",
        "        combined_summary, overview_component=overview_qa\n",
        "    )\n",
        "    # Clean and format the project overview text\n",
        "    project_overview = get_description_data(project_overview)\n",
        "    project_overview_markdown = (\n",
        "        \"# Project Overview\\n\\n\"\n",
        "        + project_overview.strip().replace(\"\\n\\n\", \"\\n\\n\").replace(\"  \", \" \")\n",
        "    )\n",
        "    # Print and display the project overview\n",
        "    print(project_overview_markdown)\n",
        "    display(Markdown(project_overview_markdown))\n",
        "else:\n",
        "    print(\"No combined summary available to generate the project overview.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Key Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightrag.core.generator import Generator\n",
        "from lightrag.core.component import Component\n",
        "from lightrag.components.model_client import OllamaClient\n",
        "\n",
        "key_feature_template = r\"\"\"<SYS>\n",
        "You are an expert computer engineer specializing in project documentation and coding, with advanced knowledge of various programming technologies.\n",
        "</SYS>\n",
        "Based on the provided file summaries:\n",
        "{{input_str}},\n",
        "\n",
        "Extract and list the key features (minimum 5 features) in a concise format. Each feature should include:\n",
        "- Feature Name: A brief description of the feature and its significance.\n",
        "\n",
        "Use the following format for listing the features:\n",
        "- **Feature Name**: Description of the feature and its significance.\n",
        "\n",
        "Ensure that the features are listed clearly and concisely, highlighting the most important aspects and functionalities that define the project’s value and just give me bulletin. No explanation need before and after bulletin likes \"Here are the key features extracted from the provided code snippets:\", \"Let me know if you'd like me to help with anything else!\"\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class FeatureQA(Component):\n",
        "    \"\"\"Component for extracting key features of the project.\"\"\"\n",
        "\n",
        "    def __init__(self, model_client: OllamaClient, model_kwargs: dict):  # type: ignore\n",
        "        \"\"\"\n",
        "        Initialize the FeatureQA component.\n",
        "\n",
        "        Parameters:\n",
        "        model_client (OllamaClient): The model client used for generating features.\n",
        "        model_kwargs (dict): Additional model parameters.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.generator = Generator(\n",
        "            model_client=model_client,\n",
        "            model_kwargs=model_kwargs,\n",
        "            template=key_feature_template,\n",
        "        )\n",
        "\n",
        "    def call(self, summaries: str) -> str:\n",
        "        \"\"\"\n",
        "        Extract key features based on file summaries.\n",
        "\n",
        "        Parameters:\n",
        "        summaries (str): A string containing the combined summaries of the project files.\n",
        "\n",
        "        Returns:\n",
        "        str: A list of key features extracted from the file summaries.\n",
        "        \"\"\"\n",
        "        return self.generator.call({\"input_str\": summaries})\n",
        "\n",
        "    async def acall(self, summaries: str) -> str:\n",
        "        \"\"\"\n",
        "        Asynchronous version for extracting key features.\n",
        "\n",
        "        Parameters:\n",
        "        summaries (str): A string containing the combined summaries of the project files.\n",
        "\n",
        "        Returns:\n",
        "        str: A list of key features extracted from the file summaries.\n",
        "        \"\"\"\n",
        "        return await self.generator.acall({\"input_str\": summaries})\n",
        "\n",
        "\n",
        "def generate_key_feature(combined_summary: str, feature_component: FeatureQA) -> str:\n",
        "    \"\"\"\n",
        "    Generate a list of key features based on file summaries.\n",
        "\n",
        "    Parameters:\n",
        "    combined_summary (str): A string containing the combined summaries of the project files.\n",
        "    feature_component (FeatureQA): The component used to extract key features.\n",
        "\n",
        "    Returns:\n",
        "    str: The generated list of key features in the specified format.\n",
        "    \"\"\"\n",
        "    return feature_component.generator.call({\"input_str\": combined_summary})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "oACBjJNN6vY8",
        "outputId": "58222f3b-f72b-4968-99c9-e09dfcb67f99"
      },
      "outputs": [],
      "source": [
        "# Initialize FeatureQA component with model configuration\n",
        "feature_qa = FeatureQA(**model)\n",
        "\n",
        "if combined_summary:\n",
        "    # Generate the key features based on the combined summary\n",
        "    key_feature = generate_key_feature(summary, feature_component=feature_qa)\n",
        "\n",
        "    # Process the key features to ensure proper formatting\n",
        "    key_feature = get_description_data(key_feature)\n",
        "\n",
        "    # Create markdown format for key features\n",
        "    key_feature_markdown = \"# Key Features\\n\" + key_feature\n",
        "\n",
        "    # Print the key features in markdown format\n",
        "    print(key_feature_markdown)\n",
        "\n",
        "    # Display the key features in a Markdown view (for environments that support it)\n",
        "    display(Markdown(key_feature_markdown))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Getting Started\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightrag.core.generator import Generator\n",
        "from lightrag.core.component import Component\n",
        "from lightrag.components.model_client import OllamaClient\n",
        "\n",
        "# Define the template for generating installation instructions\n",
        "installation_template = r\"\"\"<SYS>\n",
        "You are a highly skilled software engineer with expertise in documentation and project setup. You are adept at analyzing project summaries and folder structures to create clear installation instructions.\n",
        "</SYS>\n",
        "Based on the following project summary and folder structure:\n",
        "Summary:\n",
        "{{project_summary}}\n",
        "\n",
        "Folder Structure:\n",
        "{{folder_structure}}\n",
        "\n",
        "GitHub repo Link:\n",
        "{{repo_link}}\n",
        "\n",
        "Create a detailed installation guide that includes:\n",
        "1. **Prerequisites**: List any software, tools, or environment setups required before installation (e.g., Node.js, Docker) and provide link to download or install them.\n",
        "2. **Setup Instructions**: Step-by-step instructions to set up the project, including installing dependencies, configuring environment variables, and any other necessary setup.\n",
        "3. **Running the Project**: Detailed commands and steps to run the project locally, including any necessary build steps or configuration commands.\n",
        "4. **Troubleshooting**: Common issues that may arise during installation and how to resolve them.\n",
        "Ensure that the installation guide is comprehensive and easy to follow for someone new to the project and properly format them with heading like # Getting Started, ## Prerequisites, ## Installation, ## Running the Project, ## Tests, ## Troubleshooting\n",
        "Summary:\"\"\"\n",
        "\n",
        "\n",
        "class InstallationQA(Component):\n",
        "    \"\"\"Component for generating installation instructions.\"\"\"\n",
        "\n",
        "    def __init__(self, model_client: OllamaClient, model_kwargs: dict):  # type: ignore\n",
        "        \"\"\"\n",
        "        Initialize the InstallationQA component.\n",
        "\n",
        "        Parameters:\n",
        "        - model_client (OllamaClient): The client to interact with the model.\n",
        "        - model_kwargs (dict): Additional arguments for the model.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Create a Generator instance with the provided model client and template\n",
        "        self.generator = Generator(\n",
        "            model_client=model_client,\n",
        "            model_kwargs=model_kwargs,\n",
        "            template=installation_template,\n",
        "        )\n",
        "\n",
        "    def call(self, project_summary: str, folder_structure: str, repo_link: str) -> str:\n",
        "        \"\"\"\n",
        "        Generate installation guide based on project summary, folder structure, and repo link.\n",
        "\n",
        "        Parameters:\n",
        "        - project_summary (str): Summary of the project.\n",
        "        - folder_structure (str): Structure of the project folders.\n",
        "        - repo_link (str): URL of the GitHub repository.\n",
        "\n",
        "        Returns:\n",
        "        - str: The generated installation guide.\n",
        "        \"\"\"\n",
        "        return self.generator.call(\n",
        "            {\n",
        "                \"project_summary\": project_summary,\n",
        "                \"folder_structure\": folder_structure,\n",
        "                \"repo_link\": repo_link,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    async def acall(\n",
        "        self, project_summary: str, folder_structure: str, repo_link: str\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Asynchronous version for generating installation guide.\n",
        "\n",
        "        Parameters:\n",
        "        - project_summary (str): Summary of the project.\n",
        "        - folder_structure (str): Structure of the project folders.\n",
        "        - repo_link (str): URL of the GitHub repository.\n",
        "\n",
        "        Returns:\n",
        "        - str: The generated installation guide.\n",
        "        \"\"\"\n",
        "        return await self.generator.acall(\n",
        "            {\n",
        "                \"project_summary\": project_summary,\n",
        "                \"folder_structure\": folder_structure,\n",
        "                \"repo_link\": repo_link,\n",
        "            }\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L1ekRU_n6vY8",
        "outputId": "3281c640-d1a4-4998-cff2-e55bd5f2cf2b"
      },
      "outputs": [],
      "source": [
        "def generate_installation_guide(\n",
        "    project_summary: str,\n",
        "    folder_structure: str,\n",
        "    repo_link: str,\n",
        "    installation_component: InstallationQA,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Generate a comprehensive installation guide for the project.\n",
        "\n",
        "    Parameters:\n",
        "    - project_summary (str): Summary of the project.\n",
        "    - folder_structure (str): Structure of the project folders.\n",
        "    - repo_link (str): URL of the GitHub repository.\n",
        "    - installation_component (InstallationQA): Component for generating the installation guide.\n",
        "\n",
        "    Returns:\n",
        "    - str: The generated installation guide.\n",
        "    \"\"\"\n",
        "    return installation_component.call(project_summary, folder_structure, repo_link)\n",
        "\n",
        "\n",
        "# Initialize InstallationQA component with model configuration\n",
        "installation_qa = InstallationQA(**model)\n",
        "\n",
        "if combined_summary:\n",
        "    # Generate the installation guide using the provided summaries and folder structure\n",
        "    installation_guide = generate_installation_guide(\n",
        "        combined_summary,\n",
        "        folder_structure_str,\n",
        "        repository_url,\n",
        "        installation_component=installation_qa,\n",
        "    )\n",
        "    # Process the generated guide (e.g., clean or format the content)\n",
        "    installation_guide = get_description_data(installation_guide)\n",
        "\n",
        "    # Format and display the installation guide in Markdown\n",
        "    installation_guide_markdown = installation_guide\n",
        "    print(installation_guide_markdown)\n",
        "    display(Markdown(installation_guide_markdown))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### API Reference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightrag.core.generator import Generator\n",
        "from lightrag.core.component import Component\n",
        "\n",
        "\n",
        "# Define the template for API reference extraction\n",
        "api_template_v1 = r\"\"\"<SYS>\n",
        "You are an API reference extraction assistant specialized in coding files.\n",
        "</SYS>\n",
        "Please extract the API reference from the following code and provide the following information:\n",
        "1. API endpoint\n",
        "2. Purpose of the API\n",
        "3. Parameters\n",
        "4. Parameter types\n",
        "5. Parameter descriptions\n",
        "6. HTTP method\n",
        "\n",
        "Format:\n",
        "\n",
        "#### {Purpose of the API}\n",
        "\n",
        "```http\n",
        "  {HTTP method} {API endpoint}\n",
        "```\n",
        "\n",
        "| Parameter | Type     | Description                |\n",
        "| :-------- | :------- | :------------------------- |\n",
        "{parameter_rows}\n",
        "\n",
        "Example:\n",
        "\n",
        "#### Get all items\n",
        "\n",
        "```http\n",
        "  GET /api/items\n",
        "```\n",
        "\n",
        "| Parameter | Type     | Description                |\n",
        "| :-------- | :------- | :------------------------- |\n",
        "| `api_key` | `string` | **Required**. Your API key |\n",
        "| `limit`   | `integer`| **Optional**. Limit the number of items |\n",
        "\n",
        "\n",
        "If there is no API Reference, please return \"No API Reference\". No description needed in that case. Avoid asking for response like this \"Let me know if you'd like me to clarify anything!\" and write the Notes in third person narrative\n",
        "\n",
        "Code:\n",
        "{{input_str}}\n",
        "\"\"\"\n",
        "\n",
        "# Define the template for API reference extraction\n",
        "api_template = r\"\"\"\n",
        "You are an API reference extraction assistant specializing in coding files. Your task is to identify and extract information about HTTP API methods from the provided code. Focus only on endpoints that use HTTP methods (GET, POST, PUT, DELETE, etc.).\n",
        "\n",
        "For each API reference found, provide the following details:\n",
        "1. API endpoint\n",
        "2. Purpose of the API\n",
        "3. Parameters\n",
        "4. Parameter types\n",
        "5. Parameter descriptions\n",
        "6. HTTP method\n",
        "\n",
        "If the code does not include any API references or if no HTTP methods are present, return \"No API Reference.\"\n",
        "\n",
        "Format:\n",
        "\n",
        "#### {Purpose of the API}\n",
        "\n",
        "```http\n",
        "  {HTTP method} {API endpoint}\n",
        "```\n",
        "\n",
        "| Parameter | Type     | Description                |\n",
        "| :-------- | :------- | :------------------------- |\n",
        "{parameter_rows}\n",
        "\n",
        "Example:\n",
        "\n",
        "#### Get all items\n",
        "\n",
        "```http\n",
        "  GET /api/items\n",
        "```\n",
        "\n",
        "| Parameter | Type     | Description                |\n",
        "| :-------- | :------- | :------------------------- |\n",
        "| `api_key` | `string` | **Required**. Your API key |\n",
        "| `limit`   | `integer`| **Optional**. Limit the number of items |\n",
        "\n",
        "Code:\n",
        "{{input_str}}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class APIReferenceExtractorQA(Component):\n",
        "    \"\"\"Component for extracting API references from code.\"\"\"\n",
        "\n",
        "    def __init__(self, model_client: OllamaClient, model_kwargs: dict):  # type: ignore\n",
        "        super().__init__()\n",
        "        self.generator = Generator(\n",
        "            model_client=model_client,\n",
        "            model_kwargs=model_kwargs,\n",
        "            template=api_template,\n",
        "        )\n",
        "\n",
        "    def call(self, input: str) -> str:\n",
        "        \"\"\"Extract API references from the provided code.\"\"\"\n",
        "        return self.generator.call({\"input_str\": input})\n",
        "\n",
        "    async def acall(self, input: str) -> str:\n",
        "        \"\"\"Asynchronous extraction of API references.\"\"\"\n",
        "        return await self.generator.acall({\"input_str\": input})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWg8Ih0o6vY8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "from tqdm import tqdm\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "\n",
        "def generate_api_reference(\n",
        "    path: Path,\n",
        "    ignore_list: List[str],\n",
        "    api_reference_extractor_component: APIReferenceExtractorQA,\n",
        "    api_ignore_extensions: List[str],\n",
        ") -> List[Dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Generate an API reference of files in the given path using the model.\n",
        "\n",
        "    This function processes files in the specified directory, excluding those\n",
        "    listed in the ignore list and files with extensions specified in\n",
        "    `api_ignore_extensions`. It uses the `APIReferenceExtractorQA` component\n",
        "    to extract API references from the file content.\n",
        "\n",
        "    Parameters:\n",
        "    path (Path): The directory path containing the files to process.\n",
        "    ignore_list (List[str]): List of folder names or file names to ignore.\n",
        "    api_reference_extractor_component (APIReferenceExtractorQA): The component used to extract API references.\n",
        "    api_ignore_extensions (List[str]): List of file extensions to ignore.\n",
        "\n",
        "    Returns:\n",
        "    List[Dict[str, str]]: A list of dictionaries where each dictionary contains\n",
        "    the file path and the extracted API reference or an error message.\n",
        "    \"\"\"\n",
        "    api_reference = []\n",
        "    files_to_process = []\n",
        "\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        relative_root = os.path.relpath(root, path)\n",
        "\n",
        "        # Skip directories that are in the ignore list\n",
        "        if any(ignored in relative_root.split(os.sep) for ignored in ignore_list):\n",
        "            continue\n",
        "\n",
        "        for file in files:\n",
        "            file_path = Path(root) / file\n",
        "\n",
        "            # Skip files that are in the ignore list or have ignored extensions\n",
        "            if any(ignored in file_path.parts for ignored in ignore_list):\n",
        "                continue\n",
        "\n",
        "            if any(ignore in file_path.name for ignore in specific_ignores_api):\n",
        "                continue\n",
        "\n",
        "            if file_path.suffix.lower() in api_ignore_extensions:\n",
        "                continue\n",
        "\n",
        "            files_to_process.append(file_path)\n",
        "\n",
        "    # Create a progress bar for processing files\n",
        "    pbar = tqdm(files_to_process, unit=\"file\")\n",
        "    for file_path in pbar:\n",
        "        # Update the progress bar description\n",
        "        pbar.set_description(f\"Processing files - {file_path}\")\n",
        "        try:\n",
        "            with open(file_path, \"r\") as f:\n",
        "                file_content = f.read()\n",
        "\n",
        "            # Extract API references from the file content\n",
        "            api_text = api_reference_extractor_component.call(file_content)\n",
        "            api_reference.append({\"file\": file_path, \"api_reference\": api_text})\n",
        "        except Exception as e:\n",
        "            # Append an error message if file processing fails\n",
        "            api_reference.append(\n",
        "                {\"file\": file_path, \"api_reference\": f\"Error processing file: {str(e)}\"}\n",
        "            )\n",
        "\n",
        "    return api_reference\n",
        "\n",
        "\n",
        "# Initialize APIReferenceExtractorQA component with model configuration\n",
        "api_reference_extractor_qa = APIReferenceExtractorQA(**model)\n",
        "\n",
        "if cloned_repo_path:\n",
        "    path = Path(cloned_repo_path)\n",
        "    if not path.is_dir():\n",
        "        print(f\"The path {path} is not a directory.\")\n",
        "    api_reference = generate_api_reference(\n",
        "        path,\n",
        "        ignore_list=ignore_list_folder_structure,\n",
        "        api_reference_extractor_component=api_reference_extractor_qa,\n",
        "        api_ignore_extensions=api_ignore_extensions,\n",
        "    )\n",
        "\n",
        "    # Initialize PrettyTable for formatted output\n",
        "    api_table = PrettyTable()\n",
        "    api_table.field_names = [\"File\", \"API Reference\"]\n",
        "\n",
        "    # Create a list to hold data for further processing (e.g., saving to Excel)\n",
        "    api_data_for_excel = []\n",
        "\n",
        "    for item in api_reference:\n",
        "        # Process the API reference text to get description data\n",
        "        description_data = get_description_data(item[\"api_reference\"])\n",
        "        if \"No API Reference\" in description_data:\n",
        "            continue\n",
        "        # Add rows to the PrettyTable\n",
        "        api_table.add_row([item[\"file\"], description_data])\n",
        "        api_data_for_excel.append(\n",
        "            {\"File\": item[\"file\"], \"api_reference\": description_data}\n",
        "        )\n",
        "\n",
        "    # Print the PrettyTable\n",
        "    print(api_table)\n",
        "else:\n",
        "    print(\"Repository cloning failed or was skipped.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFf-vXfGilGk",
        "outputId": "ec73280c-8bb2-4901-a65e-01841515158a"
      },
      "outputs": [],
      "source": [
        "for item in api_reference:\n",
        "    # Check if the item is a dictionary and contains the 'api_reference' key\n",
        "    if isinstance(item, dict) and \"api_reference\" in item:\n",
        "        description_data = get_description_data(item[\"api_reference\"])\n",
        "\n",
        "        # Skip items with no API reference\n",
        "        if \"No API Reference\" in description_data:\n",
        "            continue\n",
        "\n",
        "        # Add valid items to the PrettyTable\n",
        "        api_table.add_row([item[\"file\"], description_data])\n",
        "        api_data_for_excel.append(\n",
        "            {\"File\": item[\"file\"], \"api_reference\": description_data}\n",
        "        )\n",
        "    else:\n",
        "        # Print a message if the item format is unexpected\n",
        "        print(f\"Unexpected item format: {item}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "#### API Reference Data Export\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvJqFhRY6vY8",
        "outputId": "34012952-2b94-41c4-f4b7-243d0deda435"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "if api_data_for_excel:\n",
        "    # Convert the list of dictionaries to a DataFrame\n",
        "    df_api_data = pd.DataFrame(api_data_for_excel)\n",
        "\n",
        "    # Define the path and name for the Excel file\n",
        "    excel_path = f\"output/{metadata.name}_api_reference.xlsx\"\n",
        "\n",
        "    # Save the DataFrame to an Excel file with the specified path\n",
        "    df_api_data.to_excel(excel_path, index=False, engine=\"openpyxl\")\n",
        "\n",
        "    # Print a confirmation message with the file path\n",
        "    print(f\"API reference data saved to {excel_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "#### API Reference Markdown\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7-yUfL68cGOT",
        "outputId": "b5565862-0294-4599-ce8d-cf95f397e019"
      },
      "outputs": [],
      "source": [
        "# Convert to string in the desired format\n",
        "api_reference_markdown = \"# API Reference\\n\\n\"\n",
        "for i, entry in enumerate(api_data_for_excel, start=1):\n",
        "    file = entry[\"File\"]\n",
        "    api_reference = entry[\"api_reference\"]\n",
        "    # Append formatted API reference to the markdown string\n",
        "    api_reference_markdown += f\"**File:** {file}\\n\\n{api_reference}\\n\\n\"\n",
        "\n",
        "print(api_reference_markdown)\n",
        "display(Markdown(api_reference_markdown))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Contributing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6JBcgCTmn-XF",
        "outputId": "35f3c7b4-da35-4975-f9f7-edfda3c8a446"
      },
      "outputs": [],
      "source": [
        "def generate_contributing_guide(repo_link):\n",
        "    \"\"\"\n",
        "    Generate a contributing guide for a GitHub repository.\n",
        "\n",
        "    Parameters:\n",
        "    repo_link (str): The URL of the GitHub repository.\n",
        "\n",
        "    Returns:\n",
        "    str: The contributing guide in markdown format.\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    # Extract the username and repository name from the link\n",
        "    match = re.match(r\"https://github.com/([^/]+)/([^/]+)\", repo_link)\n",
        "    if not match:\n",
        "        raise ValueError(\"Invalid GitHub repository link\")\n",
        "\n",
        "    username, repo_name = match.groups()\n",
        "\n",
        "    # Define the guide with placeholders for URLs\n",
        "    guide_template = f\"\"\"\n",
        "# Contributing\n",
        "\n",
        "Contributions are welcome! Here are several ways you can contribute:\n",
        "\n",
        "- **[Submit Pull Requests](https://github.com/{username}/{repo_name}/pulls)**: Review open PRs, and submit your own PRs.\n",
        "- **[Join the Discussions](https://github.com/{username}/{repo_name}/discussions)**: Share your insights, provide feedback, or ask questions.\n",
        "- **[Report Issues](https://github.com/{username}/{repo_name}/issues)**: Submit bugs found or log feature requests for {repo_name}.\n",
        "\n",
        "### Contributing Guidelines\n",
        "\n",
        "1. **Fork the Repository**:\n",
        "    - Start by forking the project repository to your GitHub account.\n",
        "2. **Clone the Repository**:\n",
        "    - Clone your forked repository to your local machine using the command:\n",
        "    ```sh\n",
        "    git clone https://github.com/your-username/{repo_name}.git\n",
        "    ```\n",
        "    - Replace ``your-username`` with your GitHub username.\n",
        "3. **Create a New Branch**:\n",
        "    - Create a new branch for your changes using the command:\n",
        "    ```sh\n",
        "    git checkout -b your-branch-name\n",
        "    ```\n",
        "4. **Make Your Changes**:\n",
        "    - Edit, add, or delete files as needed. Ensure your changes align with the project's contribution guidelines.\n",
        "5. **Commit Your Changes**:\n",
        "    - Stage your changes and commit them with a descriptive message:\n",
        "      ```bash\n",
        "      git add .\n",
        "      git commit -m \"Your descriptive message\"\n",
        "      ```\n",
        "6. **Push Your Changes:**\n",
        "    - Push your branch to your forked repository:\n",
        "      ```bash\n",
        "      git push origin your-branch-name\n",
        "      ```\n",
        "7. **Create a Pull Request (PR):**\n",
        "    - Go to the original repository on GitHub and click “Compare & pull request.” Provide a clear description of the changes and submit the PR.\n",
        "\n",
        "Once your PR is reviewed and approved, it will be merged into the main branch.\n",
        "    \"\"\"\n",
        "\n",
        "    return guide_template\n",
        "\n",
        "\n",
        "# Generate the contributing guide for the given repository URL\n",
        "contribution_markdown = generate_contributing_guide(repository_url)\n",
        "print(contribution_markdown)\n",
        "display(Markdown(contribution_markdown))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Contributors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "9tUl8b3NFGy9",
        "outputId": "46a63be5-85ab-4141-9b02-64706acf0833"
      },
      "outputs": [],
      "source": [
        "def generate_contributors_table(contributors):\n",
        "    \"\"\"\n",
        "    Generate a markdown table of contributors with their avatars, GitHub profiles, and contribution counts.\n",
        "\n",
        "    Parameters:\n",
        "    contributors (list): A list of contributor objects with attributes 'avatar_url', 'name', 'profile_url', and 'contributions'.\n",
        "\n",
        "    Returns:\n",
        "    str: The contributors table in markdown format.\n",
        "    \"\"\"\n",
        "    # Start with the table header\n",
        "    table = \"| Avatar | Contributor | GitHub Profile | No of Contributions |\\n\"\n",
        "    table += \"|:--------:|:--------------:|:----------------:|:-------------------:|\\n\"\n",
        "\n",
        "    # Add each contributor to the table\n",
        "    for contributor in contributors:\n",
        "        table += (\n",
        "            f\"| <img src='{contributor.avatar_url}' width='40' height='40' style='border-radius:50%;'/> | \"\n",
        "            f\"{contributor.name} | \"\n",
        "            f\"[@{contributor.name}]({contributor.profile_url}) | \"\n",
        "            f\"{contributor.contributions} |\\n\"\n",
        "        )\n",
        "\n",
        "    return table\n",
        "\n",
        "\n",
        "# Example usage for generating contributors markdown\n",
        "contributor_markdown = f\"\"\"\n",
        "# Contributors\\n\n",
        "{generate_contributors_table(metadata.contributors)}\n",
        "    \"\"\"\n",
        "print(contributor_markdown)\n",
        "display(Markdown(contributor_markdown))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### License\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jjh4wB-p_j-"
      },
      "outputs": [],
      "source": [
        "license_markdown = \"\"\"\n",
        "# License\n",
        "\n",
        "This project is licensed under the MIT License - see the [LICENSE](./LICENSE) file for details.\n",
        "\"\"\"\n",
        "\n",
        "# Display the license information\n",
        "print(license_markdown)\n",
        "display(Markdown(license_markdown))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMybv7gx6vY9"
      },
      "source": [
        "<!-- @format -->\n",
        "\n",
        "# Markdown\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Combine and Save README Content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dtsDiZMx6vY-",
        "outputId": "26ad0313-1b95-430c-97d8-67d46dbd3ac0"
      },
      "outputs": [],
      "source": [
        "# Combine all markdown sections into a single markdown string\n",
        "combined_markdown = (\n",
        "    header_markdown\n",
        "    + \"\\n\\n---\\n\"\n",
        "    + project_overview_markdown\n",
        "    + \"\\n\\n---\\n\"\n",
        "    + key_feature_markdown\n",
        "    + \"\\n\\n---\\n\"\n",
        "    + folder_structure_markdown\n",
        "    + \"\\n\\n---\\n\"\n",
        "    + installation_guide_markdown\n",
        "    + \"\\n\\n---\\n\"\n",
        "    + api_reference_markdown\n",
        "    + \"\\n\\n---\\n\"\n",
        "    + contribution_markdown\n",
        "    + \"\\n\\n---\\n\"\n",
        "    + contributor_markdown\n",
        "    + \"\\n\\n---\\n\"\n",
        "    + license_markdown\n",
        "    + \"\\n\\n---\\n\"\n",
        ")\n",
        "\n",
        "# Display the combined markdown\n",
        "print(combined_markdown)\n",
        "display(Markdown(combined_markdown))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- @format -->\n",
        "\n",
        "### Save README to File\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opqW4Psw6vY-",
        "outputId": "12c4840f-56e9-4cba-d31a-d998476f8e49"
      },
      "outputs": [],
      "source": [
        "# Specify the file name\n",
        "file_name = f\"output/{metadata.name}_README.md\"\n",
        "\n",
        "# Open the file in write mode with utf-8 encoding and save the content\n",
        "with open(file_name, \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(str(combined_markdown))\n",
        "\n",
        "print(f\"{file_name} has been created and saved.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
